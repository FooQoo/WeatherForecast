{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "タイトル : \n",
    "気象庁データから翌日の天気を予測するkaggleぽいことをしてみた\n",
    "tag :\n",
    "python pandas sklearn kaggle 機械学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "こんにちは，Mt.Happyです．  \n",
    "ただいま就活中でデータ分析系のお仕事を探しています．私に興味のある方は[Mt_Happy0506](https://twitter.com/Mt_Happy0506)までご連絡ください笑  \n",
    "本題ですが，みなさん[kaggle](https://www.kaggle.com)ってご存知ですか?  \n",
    "僕もあまり詳しくはないですが，データマイニングのモデルの精度を競うコンペサイトみたいですね．  \n",
    "ちなみに僕自身は[タイタニックのコンペ](https://www.kaggle.com/c/titanic)には参加したことがあります(お察しください)  \n",
    "\n",
    "今回のエントリーでは実際にkaggleをやるわけではないのですが，我々でも簡単に手に入るデータからkaggleっぽい遊びをやってみようというテーマでお送り致します．  \n",
    "\n",
    "# 気象庁データから翌日の天気を予測する\n",
    "このテーマでやってみようと思います．  \n",
    "データは[気象庁のホームページ](http://www.data.jma.go.jp/gmd/risk/obsdl/)から入手しました．  \n",
    "こちらのサイトでは，地点・項目・期間を任意に設定して気象に関するデータを獲得できます．  \n",
    "今回は以下の設定でデータを入手しました．  \n",
    "\n",
    "| 地点 | 項目 | 期間 |\n",
    "|:--:|:--:|:--:|\n",
    "| 東京 | 気温(平均・最高・最低), 降水量, 日照時間, 日射量, 風速(平均・最大・最大瞬間), 蒸気圧, <br>相対湿度, 気圧(現地・海面), 雲量, 天気概況(昼) | 2007~2017年における<br>9/31~10/31 |\n",
    "\n",
    "予測する項目(目的変数)は天気概況(昼)で特徴量(説明変数)がそれ以外の項目にあたります．  \n",
    "以上のデータは，先ほどのホームページからcsv形式でダウンロードできます．ここからこのcsvファイルを読み取り処理していくのですが，ダウンロードしたての生の状態では，ダウンロード時刻や品質番号，均質番号といった余分な項目が含まれているため，こういったものをあらかじめexcelを使って取り除きました．  \n",
    "また翌日の天気を予測するタスクのため，日付と天気概況は一日分進めます．成形後は以下のイメージ．\n",
    "\n",
    "|年月日|特徴量項目(気温etc...)|天気概況(昼：06時〜18時)|\n",
    "|:--:|:--:|:--:|\n",
    "|2007/10/1|hogehoge|曇時々雨|\n",
    "\n",
    "それとcsvファイルは文字コードがshift-jisなのでutf-8に変更することもお忘れなく．(nkfとかツールで)  \n",
    "\n",
    "## csvファイルを読み込もう\n",
    "pandasを使ってcsvファイルを読み込みます．今回はindexとして日付型のデータを用いているのでindex及びparse_datesに'年月日'を指定しましょう．これで，indexがdatetime型で扱えます．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data_tokyo.csv', index_col='年月日', parse_dates=['年月日'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目的変数の成形\n",
    "今回のデータでは目的変数である天気概況が詳細に記述されているので，おおざっぱに「晴・曇・雨」に分類します．  \n",
    "データをよく眺めてみると，大雨や晴時々曇のように記述にはパターンがあり，接続詞的なものに「'後','一時','時々',' 、'」が使われていることがわかります．  \n",
    "\n",
    "また修飾語がついている場合は，各トークンの最後の文字に注目するとそれが「晴・曇・雨」のいずれかの文字が使われています．  \n",
    "よって正規表現や文字列のインデックスの指定で「晴・曇・雨」に分類できそうです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "晴    143\n",
       "曇    141\n",
       "雨     57\n",
       "Name: 天気概況(昼：06時〜18時), dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import datetime\n",
    "\n",
    "#以降，目的変数はcolで指定します．\n",
    "col = '天気概況(昼：06時〜18時)'\n",
    "\n",
    "df[col] = df[col].apply(lambda x:re.split('[後|一時|時々|、]',x)[0][-1])\n",
    "\n",
    "#分類できたか確認\n",
    "df[col].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "無事，「晴・曇・雨」に分類できました!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ついでに目的変数のラベルを整数に変換します．dataframeの型も忘れずに(これのせいで学習時にエラーが発生し問題解決に1時間とられました...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルを整数に変換\n",
    "df.loc[df[col]=='晴',col] = 0\n",
    "df.loc[df[col]=='曇',col] = 1\n",
    "df.loc[df[col]=='雨',col] = 2\n",
    "\n",
    "#目的変数の型変換\n",
    "df.loc[:,[col]]=df.loc[:,[col]].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの分割\n",
    "さて次に訓練データとテストデータを分割します．今回は，天気を予測するということで，2017年のデータを2007~2016年のデータに分割します．  \n",
    "訓練データを2016年以前に，テストデータを2017年のものとします．(indexが日付型なのでこの作業は簡単)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf = df.loc[:'2016',:]\n",
    "testdf = df.loc['2017':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "またそれぞれ説明変数と目的変数でも分割します．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dlist = [col,'最高気温(℃)','降水量の合計(mm)','平均湿度(％)','平均風速(m/s)','平均気温(℃)','最大風速(m/s)','合計全天日射量(MJ/u)']\n",
    "dlist = [col]\n",
    "X_train = traindf.loc[:'2016',:].drop(dlist,axis=1).values\n",
    "y_train = traindf.loc[:'2016',col].values\n",
    "\n",
    "X_test = testdf.loc['2017':,:].drop(dlist,axis=1).values\n",
    "y_test = testdf.loc['2017':,col].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特徴量の標準化\n",
    "[ランダムフォレスト](https://ja.wikipedia.org/wiki/ランダムフォレスト)を使う場合だと，ほぼやる必要は無いですが，境界面を作っていくタイプのモデル(重回帰分析,ロジスティック回帰,SVMとか?)だとデータを標準化する方が予測精度が上がりやすい知見があるのでやります．(標準化についてはググればブログやwikiで解説があります)  \n",
    "scikit-learnではこの標準化が以下のコードで簡単に行えます.  \n",
    "ただしテストデータは未知データであるという前提があるため，標準化における平均と分散の計算には用いてはいけません．(重要)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#標準化させるために訓練データだけで平均と分散を計算\n",
    "scaler.fit(X_train)\n",
    "#訓練データ，テストデータを標準化する．\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## とりあえず学習\n",
    "では一旦，ここまでで獲得したデータからモデルを作成してみます．  \n",
    "モデルはscikit-learnに標準装備されてるサポートベクターマシン(SVM)で行いました．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(class_weight='balanced',random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## とりあえず評価\n",
    "まぁ評価してみましょう．各ラベルの予測精度の平均はモデルのメソッドであるscoreで確認できます．  \n",
    "またそれぞれの予測精度はscikit-learnのclassification_reportで確認できます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均予測精度 : 0.3870967741935484\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          晴       0.29      0.25      0.27         8\n",
      "          曇       0.33      0.10      0.15        10\n",
      "          雨       0.43      0.69      0.53        13\n",
      "\n",
      "avg / total       0.36      0.39      0.34        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('平均予測精度 : {}\\n'.format(clf.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=['晴','曇','雨']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "めちゃくちゃ悪いですね笑 特に雨は全く予測できてません，，，  \n",
    "当てずっぽで3分の1なんでそれより低いのは使い物になりません．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作戦変更...とりあえず晴れだけでも予測したい\n",
    "上の通りです．というわけでラベルを以下のものに書き換えました．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ラベルを整数に変換\n",
    "df.loc[df[col]=='晴',col] = 1\n",
    "df.loc[df[col]=='曇',col] = 0\n",
    "df.loc[df[col]=='雨',col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均予測精度 : 0.7096774193548387\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       曇or雨       0.77      0.87      0.82        23\n",
      "          晴       0.40      0.25      0.31         8\n",
      "\n",
      "avg / total       0.67      0.71      0.69        31\n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#目的変数の型変換\n",
    "df.loc[:,[col]]=df.loc[:,[col]].astype(int)\n",
    "traindf = df.loc[:'2016',:]\n",
    "testdf = df.loc['2017':]\n",
    "#dlist = [col,'最高気温(℃)','降水量の合計(mm)','平均湿度(％)','平均風速(m/s)','平均気温(℃)','最大風速(m/s)','合計全天日射量(MJ/u)']\n",
    "dlist = [col]\n",
    "X_train = traindf.loc[:'2016',:].drop(dlist,axis=1).values\n",
    "y_train = traindf.loc[:'2016',col].values\n",
    "\n",
    "X_test = testdf.loc['2017':,:].drop(dlist,axis=1).values\n",
    "y_test = testdf.loc['2017':,col].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#標準化させるために訓練データだけで平均と分散を計算\n",
    "scaler.fit(X_train)\n",
    "#訓練データ，テストデータを標準化する．\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('平均予測精度 : {}\\n'.format(clf.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=['曇or雨','晴']))\n",
    "\n",
    "X_train = traindf.loc[:'2016',:].drop(dlist,axis=1).values\n",
    "y_train = traindf.loc[:'2016',col].values\n",
    "\n",
    "X_test = testdf.loc['2017':,:].drop(dlist,axis=1).values\n",
    "y_test = testdf.loc['2017':,col].values\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "少しまともに見えますね笑"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータチュニーングする\n",
    "### パラメータについて\n",
    "モデルを構築する際のキモになるところです．  \n",
    "今回利用する学習モデルのSVMには，境界面の複雑さを制御するパラメータとして$C$と$\\alpha$があります．  \n",
    "僕のイメージでは，Cとgammaが高いほどoverfittingする感じです．([こちらのサイト](https://qiita.com/sz_dr/items/f3d6630137b184156a67)でわかりやすく解説)  \n",
    "またそれぞれのクラスのサンプル数に偏りがあるデータ(不均衡なデータ)の場合，片方の分類精度が極端に悪くなってしまう場合があります．(参考:[unbalanced-problems](http://scikit-learn.org/0.18/modules/svm.html#unbalanced-problems))  \n",
    "\n",
    "そこで各クラスでバランス良く重み付けしてくれるclass_weight='balanced'を設定するか否かという点についてもチューニングして判断します．  \n",
    "### 時系列データにおける交差検証の注意点\n",
    "交差検証についての説明は割愛しますが，今回の場合は一般的なランダム抽出の交差検証ではなく，各年度ごとにグループを作成して行います．  \n",
    "このアプローチをとった理由は，時系列データは自己相似性があり，indexの近いデータ同士は類似しやすい特性があるためです．  \n",
    "したがって，ある年度のデータをその他の年度のデータを用いて予測するということを繰り返し，パラメータのチュニーングを行なっていく必要があります．  \n",
    "scikit-learnではこのための交差検証のクラスにGroupKFoldがあります．これによって作成した分割のリストをGridSearchCVの引数cvに投げることで前述した交差検証が行えます．  \n",
    "\n",
    "### 標準化と学習のパイプライン化\n",
    "標準化の項目でも説明したようにテストデータは平均と分散の計算に用いていけないという掟があります．  \n",
    "交差検証も同様で検証データ(validation data)は別に平均と分散を計算しなければなりません．  \n",
    "これをscikit-learnのグリッドサーチで実現するために，標準化と学習をパイプライン化します．  \n",
    "この関数もscikit-learnに標準装備されており，そのまんまPipelineクラスで行えます．  \n",
    "scikit-learnは本当に便利ですよね〜笑  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fukuyama/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/fukuyama/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.65\n",
      "Train set score: 0.67\n",
      "Best parameters : {'svm__class_weight': 'balanced', 'svm__gamma': 0.01, 'svm__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# group 10-fold cross validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "n = X_train.shape[1]\n",
    "\n",
    "#標準化と学習のパイプライン\n",
    "pipe = Pipeline([('scaler',StandardScaler()),(\"svm\",SVC(random_state=0))])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "#パラメータは10^nオーダーで変化させる\n",
    "params = {'svm__C':[0.0001,0.001,0.01,0.1,1,10,100],'svm__gamma':[1/n,0.001,0.01,0.1,1,10,100],'svm__class_weight':[None,'balanced']}\n",
    "#年度は31indexごとに切り替わるため\n",
    "groups = sum([[label]*31 for label in range(10)],[])\n",
    "gkfold = list(GroupKFold(n_splits=10).split(X_train,y_train,groups))\n",
    "\n",
    "#グリッドサーチ\n",
    "grid = GridSearchCV(pipe, param_grid = params, cv = gkfold, scoring='accuracy',n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best cross-validation accuracy: {:.2f}'.format(grid.best_score_))\n",
    "print('Train set score: {:.2f}'.format(grid.score(X_train,y_train)))\n",
    "print('Best parameters : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それでは，チューニングしたパラメータでテストデータを確認しましょう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均予測精度 : 0.6129032258064516\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       曇or雨       0.77      0.87      0.82        23\n",
      "          晴       0.40      0.25      0.31         8\n",
      "\n",
      "avg / total       0.67      0.71      0.69        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "clf = SVC(C=1.0, gamma=0.01, random_state=0, probability=True, class_weight='balanced')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('平均予測精度 : {}\\n'.format(clf.score(X_test, y_test)))\n",
    "print(classification_report(y_test, y_pred,target_names=['曇or雨','晴']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "チューニング前より下がってる，，，ナンテコッタ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 悲しみを乗り越えて...\n",
    "\n",
    "というわけで，まさかのチューニングしない方がよかったという結果になってしまいました笑  \n",
    "色々理由は考えられるのですが，今年のデータはこれまでに無い異常気象だったということでなんでしょうかね  \n",
    "\n",
    "今回のエントリーはここでおしまいですが，引き続き特徴量選択やらベースラインを作ってみたことについても記事にするので，  \n",
    "興味がある方は是非ご拝読くださいませ  \n",
    "\n",
    "それではまた次回!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(310, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "groups = np.array(sum([[label]*31 for label in range(10)],[]))\n",
    "\n",
    "X_train[np.where(groups==0)],y_train[np.where(groups==0)]\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 16.8 ,  18.7 ,  15.7 , ...,   7.1 ,  13.2 ,   2.  ],\n",
       "       [ 18.1 ,  19.9 ,  16.4 , ...,   4.9 ,   8.4 ,   3.8 ],\n",
       "       [ 19.8 ,  22.7 ,  17.2 , ...,   5.1 ,   7.6 ,   7.2 ],\n",
       "       ..., \n",
       "       [ 12.2 ,  14.8 ,  10.1 , ...,   4.9 ,   7.6 ,   1.46],\n",
       "       [ 15.5 ,  20.8 ,  11.6 , ...,   5.8 ,  13.6 ,   4.33],\n",
       "       [ 11.9 ,  13.5 ,   9.6 , ...,   4.7 ,   8.  ,   3.93]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fukuyama/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/tensorflow/python/util/tf_should_use.py:107: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "step=100, loss=-5241349.00\n",
      "(310, 14) (310, 1)\n",
      "step=200, loss=-10831141.00\n",
      "(310, 14) (310, 1)\n",
      "step=300, loss=-5142867.50\n",
      "(310, 14) (310, 1)\n",
      "step=400, loss=-16198750.00\n",
      "(310, 14) (310, 1)\n",
      "step=500, loss=-15827746.00\n",
      "(310, 14) (310, 1)\n",
      "step=600, loss=-24247700.00\n",
      "(310, 14) (310, 1)\n",
      "step=700, loss=-36476628.00\n",
      "(310, 14) (310, 1)\n",
      "step=800, loss=-25446052.00\n",
      "(310, 14) (310, 1)\n",
      "step=900, loss=-49377468.00\n",
      "(310, 14) (310, 1)\n",
      "step=1000, loss=-40497768.00\n",
      "(310, 14) (310, 1)\n",
      "step=1100, loss=-31846598.00\n",
      "(310, 14) (310, 1)\n",
      "step=1200, loss=-48733388.00\n",
      "(310, 14) (310, 1)\n",
      "step=1300, loss=-67897728.00\n",
      "(310, 14) (310, 1)\n",
      "step=1400, loss=-57029236.00\n",
      "(310, 14) (310, 1)\n",
      "step=1500, loss=-78610912.00\n",
      "(310, 14) (310, 1)\n",
      "step=1600, loss=-83808632.00\n",
      "(310, 14) (310, 1)\n",
      "step=1700, loss=-89284496.00\n",
      "(310, 14) (310, 1)\n",
      "step=1800, loss=-73704816.00\n",
      "(310, 14) (310, 1)\n",
      "step=1900, loss=-72096672.00\n",
      "(310, 14) (310, 1)\n",
      "step=2000, loss=-110472224.00\n",
      "(310, 14) (310, 1)\n",
      "step=2100, loss=-109883128.00\n",
      "(310, 14) (310, 1)\n",
      "step=2200, loss=-108268344.00\n",
      "(310, 14) (310, 1)\n",
      "step=2300, loss=-73389992.00\n",
      "(310, 14) (310, 1)\n",
      "step=2400, loss=-97873776.00\n",
      "(310, 14) (310, 1)\n",
      "step=2500, loss=-123051600.00\n",
      "(310, 14) (310, 1)\n",
      "step=2600, loss=-98318376.00\n",
      "(310, 14) (310, 1)\n",
      "step=2700, loss=-133163216.00\n",
      "(310, 14) (310, 1)\n",
      "step=2800, loss=-105953496.00\n",
      "(310, 14) (310, 1)\n",
      "step=2900, loss=-118277728.00\n",
      "(310, 14) (310, 1)\n",
      "step=3000, loss=-87327536.00\n",
      "(310, 14) (310, 1)\n",
      "step=3100, loss=-152293840.00\n",
      "(310, 14) (310, 1)\n",
      "step=3200, loss=-157073504.00\n",
      "(310, 14) (310, 1)\n",
      "step=3300, loss=-162088256.00\n",
      "(310, 14) (310, 1)\n",
      "step=3400, loss=-98871920.00\n",
      "(310, 14) (310, 1)\n",
      "step=3500, loss=-182581488.00\n",
      "(310, 14) (310, 1)\n",
      "step=3600, loss=-114617896.00\n",
      "(310, 14) (310, 1)\n",
      "step=3700, loss=-139738752.00\n",
      "(310, 14) (310, 1)\n",
      "step=3800, loss=-143569040.00\n",
      "(310, 14) (310, 1)\n",
      "step=3900, loss=-159079936.00\n",
      "(310, 14) (310, 1)\n",
      "step=4000, loss=-220703888.00\n",
      "(310, 14) (310, 1)\n",
      "step=4100, loss=-155125056.00\n",
      "(310, 14) (310, 1)\n",
      "step=4200, loss=-171435216.00\n",
      "(310, 14) (310, 1)\n",
      "step=4300, loss=-224930880.00\n",
      "(310, 14) (310, 1)\n",
      "step=4400, loss=-76602008.00\n",
      "(310, 14) (310, 1)\n",
      "step=4500, loss=-221369232.00\n",
      "(310, 14) (310, 1)\n",
      "step=4600, loss=-187537232.00\n",
      "(310, 14) (310, 1)\n",
      "step=4700, loss=-191567280.00\n",
      "(310, 14) (310, 1)\n",
      "step=4800, loss=-181510160.00\n",
      "(310, 14) (310, 1)\n",
      "step=4900, loss=-270487040.00\n",
      "(310, 14) (310, 1)\n",
      "step=5000, loss=-203891024.00\n",
      "(310, 14) (310, 1)\n",
      "step=5100, loss=-281252608.00\n",
      "(310, 14) (310, 1)\n",
      "step=5200, loss=-271635200.00\n",
      "(310, 14) (310, 1)\n",
      "step=5300, loss=-154196896.00\n",
      "(310, 14) (310, 1)\n",
      "step=5400, loss=-203658480.00\n",
      "(310, 14) (310, 1)\n",
      "step=5500, loss=-223847744.00\n",
      "(310, 14) (310, 1)\n",
      "step=5600, loss=-162823408.00\n",
      "(310, 14) (310, 1)\n",
      "step=5700, loss=-181185760.00\n",
      "(310, 14) (310, 1)\n",
      "step=5800, loss=-235787328.00\n",
      "(310, 14) (310, 1)\n",
      "step=5900, loss=-239853984.00\n",
      "(310, 14) (310, 1)\n",
      "step=6000, loss=-226236976.00\n",
      "(310, 14) (310, 1)\n",
      "step=6100, loss=-247810528.00\n",
      "(310, 14) (310, 1)\n",
      "step=6200, loss=-251911008.00\n",
      "(310, 14) (310, 1)\n",
      "step=6300, loss=-346145504.00\n",
      "(310, 14) (310, 1)\n",
      "step=6400, loss=-351753760.00\n",
      "(310, 14) (310, 1)\n",
      "step=6500, loss=-112774296.00\n",
      "(310, 14) (310, 1)\n",
      "step=6600, loss=-114462840.00\n",
      "(310, 14) (310, 1)\n",
      "step=6700, loss=-116130584.00\n",
      "(310, 14) (310, 1)\n",
      "step=6800, loss=-117863168.00\n",
      "(310, 14) (310, 1)\n",
      "step=6900, loss=-259448112.00\n",
      "(310, 14) (310, 1)\n",
      "step=7000, loss=-284005856.00\n",
      "(310, 14) (310, 1)\n",
      "step=7100, loss=-288030848.00\n",
      "(310, 14) (310, 1)\n",
      "step=7200, loss=-208796640.00\n",
      "(310, 14) (310, 1)\n",
      "step=7300, loss=-400158304.00\n",
      "(310, 14) (310, 1)\n",
      "step=7400, loss=-362133408.00\n",
      "(310, 14) (310, 1)\n",
      "step=7500, loss=-129910904.00\n",
      "(310, 14) (310, 1)\n",
      "step=7600, loss=-308260128.00\n",
      "(310, 14) (310, 1)\n",
      "step=7700, loss=-422111424.00\n",
      "(310, 14) (310, 1)\n",
      "step=7800, loss=-247112704.00\n",
      "(310, 14) (310, 1)\n",
      "step=7900, loss=-320059808.00\n",
      "(310, 14) (310, 1)\n",
      "step=8000, loss=-231737504.00\n",
      "(310, 14) (310, 1)\n",
      "step=8100, loss=-328304096.00\n",
      "(310, 14) (310, 1)\n",
      "step=8200, loss=-449358976.00\n",
      "(310, 14) (310, 1)\n",
      "step=8300, loss=-263077840.00\n",
      "(310, 14) (310, 1)\n",
      "step=8400, loss=-340627200.00\n",
      "(310, 14) (310, 1)\n",
      "step=8500, loss=-319617280.00\n",
      "(310, 14) (310, 1)\n",
      "step=8600, loss=-323391680.00\n",
      "(310, 14) (310, 1)\n",
      "step=8700, loss=-150732496.00\n",
      "(310, 14) (310, 1)\n",
      "step=8800, loss=-255083392.00\n",
      "(310, 14) (310, 1)\n",
      "step=8900, loss=-435364032.00\n",
      "(310, 14) (310, 1)\n",
      "step=9000, loss=-338186240.00\n",
      "(310, 14) (310, 1)\n",
      "step=9100, loss=-263601824.00\n",
      "(310, 14) (310, 1)\n",
      "step=9200, loss=-266456672.00\n",
      "(310, 14) (310, 1)\n",
      "step=9300, loss=-160869072.00\n",
      "(310, 14) (310, 1)\n",
      "step=9400, loss=-297414784.00\n",
      "(310, 14) (310, 1)\n",
      "step=9500, loss=-275002048.00\n",
      "(310, 14) (310, 1)\n",
      "step=9600, loss=-277815616.00\n",
      "(310, 14) (310, 1)\n",
      "step=9700, loss=-503730976.00\n",
      "(310, 14) (310, 1)\n",
      "step=9800, loss=-367673984.00\n",
      "(310, 14) (310, 1)\n",
      "step=9900, loss=-286414496.00\n",
      "(310, 14) (310, 1)\n",
      "step=10000, loss=-547086848.00\n",
      "(310, 14) (310, 1)\n",
      "step=10100, loss=-552629952.00\n",
      "(310, 14) (310, 1)\n",
      "step=10200, loss=-529523296.00\n",
      "(310, 14) (310, 1)\n",
      "step=10300, loss=-386556576.00\n",
      "(310, 14) (310, 1)\n",
      "step=10400, loss=-328926304.00\n",
      "(310, 14) (310, 1)\n",
      "step=10500, loss=-181414704.00\n",
      "(310, 14) (310, 1)\n",
      "step=10600, loss=-579527296.00\n",
      "(310, 14) (310, 1)\n",
      "step=10700, loss=-522281120.00\n",
      "(310, 14) (310, 1)\n",
      "step=10800, loss=-186546224.00\n",
      "(310, 14) (310, 1)\n",
      "step=10900, loss=-440815264.00\n",
      "(310, 14) (310, 1)\n",
      "step=11000, loss=-189992016.00\n",
      "(310, 14) (310, 1)\n",
      "step=11100, loss=-416115776.00\n",
      "(310, 14) (310, 1)\n",
      "step=11200, loss=-193455104.00\n",
      "(310, 14) (310, 1)\n",
      "step=11300, loss=-617963776.00\n",
      "(310, 14) (310, 1)\n",
      "step=11400, loss=-329576512.00\n",
      "(310, 14) (310, 1)\n",
      "step=11500, loss=-431135680.00\n",
      "(310, 14) (310, 1)\n",
      "step=11600, loss=-601613504.00\n",
      "(310, 14) (310, 1)\n",
      "step=11700, loss=-369794272.00\n",
      "(310, 14) (310, 1)\n",
      "step=11800, loss=-340983264.00\n",
      "(310, 14) (310, 1)\n",
      "step=11900, loss=-376052864.00\n",
      "(310, 14) (310, 1)\n",
      "step=12000, loss=-585536832.00\n",
      "(310, 14) (310, 1)\n",
      "step=12100, loss=-453874048.00\n",
      "(310, 14) (310, 1)\n",
      "step=12200, loss=-667291776.00\n",
      "(310, 14) (310, 1)\n",
      "step=12300, loss=-461401504.00\n",
      "(310, 14) (310, 1)\n",
      "step=12400, loss=-678244288.00\n",
      "(310, 14) (310, 1)\n",
      "step=12500, loss=-361556768.00\n",
      "(310, 14) (310, 1)\n",
      "step=12600, loss=-398337824.00\n",
      "(310, 14) (310, 1)\n",
      "step=12700, loss=-219344560.00\n",
      "(310, 14) (310, 1)\n",
      "step=12800, loss=-663869696.00\n",
      "(310, 14) (310, 1)\n",
      "step=12900, loss=-372849696.00\n",
      "(310, 14) (310, 1)\n",
      "step=13000, loss=-487360544.00\n",
      "(310, 14) (310, 1)\n",
      "step=13100, loss=-529598816.00\n",
      "(310, 14) (310, 1)\n",
      "step=13200, loss=-721526848.00\n",
      "(310, 14) (310, 1)\n",
      "step=13300, loss=-498436352.00\n",
      "(310, 14) (310, 1)\n",
      "step=13400, loss=-231410064.00\n",
      "(310, 14) (310, 1)\n",
      "step=13500, loss=-233113376.00\n",
      "(310, 14) (310, 1)\n",
      "step=13600, loss=-663876096.00\n",
      "(310, 14) (310, 1)\n",
      "step=13700, loss=-710655296.00\n",
      "(310, 14) (310, 1)\n",
      "step=13800, loss=-715915648.00\n",
      "(310, 14) (310, 1)\n",
      "step=13900, loss=-721011072.00\n",
      "(310, 14) (310, 1)\n",
      "step=14000, loss=-765879168.00\n",
      "(310, 14) (310, 1)\n",
      "step=14100, loss=-570516992.00\n",
      "(310, 14) (310, 1)\n",
      "step=14200, loss=-693270080.00\n",
      "(310, 14) (310, 1)\n",
      "step=14300, loss=-578449408.00\n",
      "(310, 14) (310, 1)\n",
      "step=14400, loss=-703040768.00\n",
      "(310, 14) (310, 1)\n",
      "step=14500, loss=-543867200.00\n",
      "(310, 14) (310, 1)\n",
      "step=14600, loss=-422316416.00\n",
      "(310, 14) (310, 1)\n",
      "step=14700, loss=-254005088.00\n",
      "(310, 14) (310, 1)\n",
      "step=14800, loss=-598754880.00\n",
      "(310, 14) (310, 1)\n",
      "step=14900, loss=-558937344.00\n",
      "(310, 14) (310, 1)\n",
      "step=15000, loss=-607025984.00\n",
      "(310, 14) (310, 1)\n",
      "step=15100, loss=-826051328.00\n",
      "(310, 14) (310, 1)\n",
      "step=15200, loss=-788904512.00\n",
      "(310, 14) (310, 1)\n",
      "step=15300, loss=-574088832.00\n",
      "(310, 14) (310, 1)\n",
      "step=15400, loss=-799245632.00\n",
      "(310, 14) (310, 1)\n",
      "step=15500, loss=-804410944.00\n",
      "(310, 14) (310, 1)\n",
      "step=15600, loss=-762077312.00\n",
      "(310, 14) (310, 1)\n",
      "step=15700, loss=-859166592.00\n",
      "(310, 14) (310, 1)\n",
      "step=15800, loss=-820188544.00\n",
      "(310, 14) (310, 1)\n",
      "step=15900, loss=-596903360.00\n",
      "(310, 14) (310, 1)\n",
      "step=16000, loss=-600628480.00\n",
      "(310, 14) (310, 1)\n",
      "step=16100, loss=-652075520.00\n",
      "(310, 14) (310, 1)\n",
      "step=16200, loss=-469000256.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=16300, loss=-659908928.00\n",
      "(310, 14) (310, 1)\n",
      "step=16400, loss=-615558784.00\n",
      "(310, 14) (310, 1)\n",
      "step=16500, loss=-285372800.00\n",
      "(310, 14) (310, 1)\n",
      "step=16600, loss=-908847040.00\n",
      "(310, 14) (310, 1)\n",
      "step=16700, loss=-914416384.00\n",
      "(310, 14) (310, 1)\n",
      "step=16800, loss=-486499104.00\n",
      "(310, 14) (310, 1)\n",
      "step=16900, loss=-925520768.00\n",
      "(310, 14) (310, 1)\n",
      "step=17000, loss=-492419744.00\n",
      "(310, 14) (310, 1)\n",
      "step=17100, loss=-541477568.00\n",
      "(310, 14) (310, 1)\n",
      "step=17200, loss=-544821760.00\n",
      "(310, 14) (310, 1)\n",
      "step=17300, loss=-501118112.00\n",
      "(310, 14) (310, 1)\n",
      "step=17400, loss=-705152512.00\n",
      "(310, 14) (310, 1)\n",
      "step=17500, loss=-302909408.00\n",
      "(310, 14) (310, 1)\n",
      "step=17600, loss=-509906144.00\n",
      "(310, 14) (310, 1)\n",
      "step=17700, loss=-969639296.00\n",
      "(310, 14) (310, 1)\n",
      "step=17800, loss=-870674496.00\n",
      "(310, 14) (310, 1)\n",
      "step=17900, loss=-672619648.00\n",
      "(310, 14) (310, 1)\n",
      "step=18000, loss=-986356928.00\n",
      "(310, 14) (310, 1)\n",
      "step=18100, loss=-733381120.00\n",
      "(310, 14) (310, 1)\n",
      "step=18200, loss=-527246944.00\n",
      "(310, 14) (310, 1)\n",
      "step=18300, loss=-316694144.00\n",
      "(310, 14) (310, 1)\n",
      "step=18400, loss=-691025152.00\n",
      "(310, 14) (310, 1)\n",
      "step=18500, loss=-694764672.00\n",
      "(310, 14) (310, 1)\n",
      "step=18600, loss=-753531200.00\n",
      "(310, 14) (310, 1)\n",
      "step=18700, loss=-757574976.00\n",
      "(310, 14) (310, 1)\n",
      "step=18800, loss=-706228480.00\n",
      "(310, 14) (310, 1)\n",
      "step=18900, loss=-1035827200.00\n",
      "(310, 14) (310, 1)\n",
      "step=19000, loss=-714177728.00\n",
      "(310, 14) (310, 1)\n",
      "step=19100, loss=-774184832.00\n",
      "(310, 14) (310, 1)\n",
      "step=19200, loss=-778210880.00\n",
      "(310, 14) (310, 1)\n",
      "step=19300, loss=-334127392.00\n",
      "(310, 14) (310, 1)\n",
      "step=19400, loss=-1062946688.00\n",
      "(310, 14) (310, 1)\n",
      "step=19500, loss=-337547392.00\n",
      "(310, 14) (310, 1)\n",
      "step=19600, loss=-736504640.00\n",
      "(310, 14) (310, 1)\n",
      "step=19700, loss=-624108992.00\n",
      "(310, 14) (310, 1)\n",
      "step=19800, loss=-802467456.00\n",
      "(310, 14) (310, 1)\n",
      "step=19900, loss=-1034431872.00\n",
      "(310, 14) (310, 1)\n",
      "step=20000, loss=-579463552.00\n",
      "(310, 14) (310, 1)\n",
      "step=20100, loss=-755496128.00\n",
      "(310, 14) (310, 1)\n",
      "step=20200, loss=-818796992.00\n",
      "(310, 14) (310, 1)\n",
      "step=20300, loss=-822980992.00\n",
      "(310, 14) (310, 1)\n",
      "step=20400, loss=-591256512.00\n",
      "(310, 14) (310, 1)\n",
      "step=20500, loss=-354954720.00\n",
      "(310, 14) (310, 1)\n",
      "step=20600, loss=-652925120.00\n",
      "(310, 14) (310, 1)\n",
      "step=20700, loss=-839345216.00\n",
      "(310, 14) (310, 1)\n",
      "step=20800, loss=-602923200.00\n",
      "(310, 14) (310, 1)\n",
      "step=20900, loss=-662465728.00\n",
      "(310, 14) (310, 1)\n",
      "step=21000, loss=-608708032.00\n",
      "(310, 14) (310, 1)\n",
      "step=21100, loss=-668688960.00\n",
      "(310, 14) (310, 1)\n",
      "step=21200, loss=-796856192.00\n",
      "(310, 14) (310, 1)\n",
      "step=21300, loss=-863396544.00\n",
      "(310, 14) (310, 1)\n",
      "step=21400, loss=-1172656512.00\n",
      "(310, 14) (310, 1)\n",
      "step=21500, loss=-622988864.00\n",
      "(310, 14) (310, 1)\n",
      "step=21600, loss=-811644416.00\n",
      "(310, 14) (310, 1)\n",
      "step=21700, loss=-628550464.00\n",
      "(310, 14) (310, 1)\n",
      "step=21800, loss=-883191040.00\n",
      "(310, 14) (310, 1)\n",
      "step=21900, loss=-693675520.00\n",
      "(310, 14) (310, 1)\n",
      "step=22000, loss=-826587584.00\n",
      "(310, 14) (310, 1)\n",
      "step=22100, loss=-382553728.00\n",
      "(310, 14) (310, 1)\n",
      "step=22200, loss=-384286784.00\n",
      "(310, 14) (310, 1)\n",
      "step=22300, loss=-1090794496.00\n",
      "(310, 14) (310, 1)\n",
      "step=22400, loss=-1164372736.00\n",
      "(310, 14) (310, 1)\n",
      "step=22500, loss=-1169485824.00\n",
      "(310, 14) (310, 1)\n",
      "step=22600, loss=-716059392.00\n",
      "(310, 14) (310, 1)\n",
      "step=22700, loss=-393003264.00\n",
      "(310, 14) (310, 1)\n",
      "step=22800, loss=-1249277440.00\n",
      "(310, 14) (310, 1)\n",
      "step=22900, loss=-928136960.00\n",
      "(310, 14) (310, 1)\n",
      "step=23000, loss=-1260470656.00\n",
      "(310, 14) (310, 1)\n",
      "step=23100, loss=-868179456.00\n",
      "(310, 14) (310, 1)\n",
      "step=23200, loss=-401804992.00\n",
      "(310, 14) (310, 1)\n",
      "step=23300, loss=-1140187520.00\n",
      "(310, 14) (310, 1)\n",
      "step=23400, loss=-678214592.00\n",
      "(310, 14) (310, 1)\n",
      "step=23500, loss=-1150182016.00\n",
      "(310, 14) (310, 1)\n",
      "step=23600, loss=-957110656.00\n",
      "(310, 14) (310, 1)\n",
      "step=23700, loss=-410528192.00\n",
      "(310, 14) (310, 1)\n",
      "step=23800, loss=-1304844032.00\n",
      "(310, 14) (310, 1)\n",
      "step=23900, loss=-1310038912.00\n",
      "(310, 14) (310, 1)\n",
      "step=24000, loss=-1247848576.00\n",
      "(310, 14) (310, 1)\n",
      "step=24100, loss=-906103104.00\n",
      "(310, 14) (310, 1)\n",
      "step=24200, loss=-1258484736.00\n",
      "(310, 14) (310, 1)\n",
      "step=24300, loss=-1263728768.00\n",
      "(310, 14) (310, 1)\n",
      "step=24400, loss=-422629024.00\n",
      "(310, 14) (310, 1)\n",
      "step=24500, loss=-710220096.00\n",
      "(310, 14) (310, 1)\n",
      "step=24600, loss=-997382080.00\n",
      "(310, 14) (310, 1)\n",
      "step=24700, loss=-928590208.00\n",
      "(310, 14) (310, 1)\n",
      "step=24800, loss=-1005888256.00\n",
      "(310, 14) (310, 1)\n",
      "step=24900, loss=-1295208320.00\n",
      "(310, 14) (310, 1)\n",
      "step=25000, loss=-792647296.00\n",
      "(310, 14) (310, 1)\n",
      "step=25100, loss=-1017861312.00\n",
      "(310, 14) (310, 1)\n",
      "step=25200, loss=-1310742912.00\n",
      "(310, 14) (310, 1)\n",
      "step=25300, loss=-1238151296.00\n",
      "(310, 14) (310, 1)\n",
      "step=25400, loss=-736300160.00\n",
      "(310, 14) (310, 1)\n",
      "step=25500, loss=-808091648.00\n",
      "(310, 14) (310, 1)\n",
      "step=25600, loss=-1331187328.00\n",
      "(310, 14) (310, 1)\n",
      "step=25700, loss=-1408685952.00\n",
      "(310, 14) (310, 1)\n",
      "step=25800, loss=-747757824.00\n",
      "(310, 14) (310, 1)\n",
      "step=25900, loss=-1049913920.00\n",
      "(310, 14) (310, 1)\n",
      "step=26000, loss=-977157056.00\n",
      "(310, 14) (310, 1)\n",
      "step=26100, loss=-1276848768.00\n",
      "(310, 14) (310, 1)\n",
      "step=26200, loss=-453700640.00\n",
      "(310, 14) (310, 1)\n",
      "step=26300, loss=-833553024.00\n",
      "(310, 14) (310, 1)\n",
      "step=26400, loss=-457192192.00\n",
      "(310, 14) (310, 1)\n",
      "step=26500, loss=-458867296.00\n",
      "(310, 14) (310, 1)\n",
      "step=26600, loss=-1301593344.00\n",
      "(310, 14) (310, 1)\n",
      "step=26700, loss=-773907776.00\n",
      "(310, 14) (310, 1)\n",
      "step=26800, loss=-1007305344.00\n",
      "(310, 14) (310, 1)\n",
      "step=26900, loss=-1011116544.00\n",
      "(310, 14) (310, 1)\n",
      "step=27000, loss=-1403918848.00\n",
      "(310, 14) (310, 1)\n",
      "step=27100, loss=-1485835904.00\n",
      "(310, 14) (310, 1)\n",
      "step=27200, loss=-1414644736.00\n",
      "(310, 14) (310, 1)\n",
      "step=27300, loss=-1496547968.00\n",
      "(310, 14) (310, 1)\n",
      "step=27400, loss=-474526368.00\n",
      "(310, 14) (310, 1)\n",
      "step=27500, loss=-796961920.00\n",
      "(310, 14) (310, 1)\n",
      "step=27600, loss=-1037409024.00\n",
      "(310, 14) (310, 1)\n",
      "step=27700, loss=-1440323200.00\n",
      "(310, 14) (310, 1)\n",
      "step=27800, loss=-481511040.00\n",
      "(310, 14) (310, 1)\n",
      "step=27900, loss=-1048843008.00\n",
      "(310, 14) (310, 1)\n",
      "step=28000, loss=-1135322624.00\n",
      "(310, 14) (310, 1)\n",
      "step=28100, loss=-1139756544.00\n",
      "(310, 14) (310, 1)\n",
      "step=28200, loss=-1060503296.00\n",
      "(310, 14) (310, 1)\n",
      "step=28300, loss=-1551797504.00\n",
      "(310, 14) (310, 1)\n",
      "step=28400, loss=-1068165248.00\n",
      "(310, 14) (310, 1)\n",
      "step=28500, loss=-903604416.00\n",
      "(310, 14) (310, 1)\n",
      "step=28600, loss=-1075393280.00\n",
      "(310, 14) (310, 1)\n",
      "step=28700, loss=-1079459456.00\n",
      "(310, 14) (310, 1)\n",
      "step=28800, loss=-1168045952.00\n",
      "(310, 14) (310, 1)\n",
      "step=28900, loss=-1087010048.00\n",
      "(310, 14) (310, 1)\n",
      "step=29000, loss=-1090692608.00\n",
      "(310, 14) (310, 1)\n",
      "step=29100, loss=-1094426240.00\n",
      "(310, 14) (310, 1)\n",
      "step=29200, loss=-1098382336.00\n",
      "(310, 14) (310, 1)\n",
      "step=29300, loss=-1524338560.00\n",
      "(310, 14) (310, 1)\n",
      "step=29400, loss=-1105625472.00\n",
      "(310, 14) (310, 1)\n",
      "step=29500, loss=-1109366016.00\n",
      "(310, 14) (310, 1)\n",
      "step=29600, loss=-1113285760.00\n",
      "(310, 14) (310, 1)\n",
      "step=29700, loss=-514555040.00\n",
      "(310, 14) (310, 1)\n",
      "step=29800, loss=-1120879488.00\n",
      "(310, 14) (310, 1)\n",
      "step=29900, loss=-1212642688.00\n",
      "(310, 14) (310, 1)\n",
      "step=30000, loss=-1216701568.00\n",
      "(310, 14) (310, 1)\n",
      "step=30100, loss=-1131912832.00\n",
      "(310, 14) (310, 1)\n",
      "step=30200, loss=-1225199104.00\n",
      "(310, 14) (310, 1)\n",
      "step=30300, loss=-1661938048.00\n",
      "(310, 14) (310, 1)\n",
      "step=30400, loss=-1233460480.00\n",
      "(310, 14) (310, 1)\n",
      "step=30500, loss=-1493254656.00\n",
      "(310, 14) (310, 1)\n",
      "step=30600, loss=-1241375872.00\n",
      "(310, 14) (310, 1)\n",
      "step=30700, loss=-1502929664.00\n",
      "(310, 14) (310, 1)\n",
      "step=30800, loss=-976606784.00\n",
      "(310, 14) (310, 1)\n",
      "step=30900, loss=-1694673408.00\n",
      "(310, 14) (310, 1)\n",
      "step=31000, loss=-1700451584.00\n",
      "(310, 14) (310, 1)\n",
      "step=31100, loss=-902006848.00\n",
      "(310, 14) (310, 1)\n",
      "step=31200, loss=-1623134976.00\n",
      "(310, 14) (310, 1)\n",
      "step=31300, loss=-1532298752.00\n",
      "(310, 14) (310, 1)\n",
      "step=31400, loss=-1273659904.00\n",
      "(310, 14) (310, 1)\n",
      "step=31500, loss=-1184577792.00\n",
      "(310, 14) (310, 1)\n",
      "step=31600, loss=-1644141056.00\n",
      "(310, 14) (310, 1)\n",
      "step=31700, loss=-1738440192.00\n",
      "(310, 14) (310, 1)\n",
      "step=31800, loss=-1556757120.00\n",
      "(310, 14) (310, 1)\n",
      "step=31900, loss=-1294300288.00\n",
      "(310, 14) (310, 1)\n",
      "step=32000, loss=-1298239616.00\n",
      "(310, 14) (310, 1)\n",
      "step=32100, loss=-1207826304.00\n",
      "(310, 14) (310, 1)\n",
      "step=32200, loss=-1021368128.00\n",
      "(310, 14) (310, 1)\n",
      "step=32300, loss=-559898176.00\n",
      "(310, 14) (310, 1)\n",
      "step=32400, loss=-1686322432.00\n",
      "(310, 14) (310, 1)\n",
      "step=32500, loss=-1030888000.00\n",
      "(310, 14) (310, 1)\n",
      "step=32600, loss=-1226422656.00\n",
      "(310, 14) (310, 1)\n",
      "step=32700, loss=-566745216.00\n",
      "(310, 14) (310, 1)\n",
      "step=32800, loss=-951510144.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=32900, loss=-1043600768.00\n",
      "(310, 14) (310, 1)\n",
      "step=33000, loss=-1241682048.00\n",
      "(310, 14) (310, 1)\n",
      "step=33100, loss=-1343082624.00\n",
      "(310, 14) (310, 1)\n",
      "step=33200, loss=-1347307904.00\n",
      "(310, 14) (310, 1)\n",
      "step=33300, loss=-1252888704.00\n",
      "(310, 14) (310, 1)\n",
      "step=33400, loss=-1635544192.00\n",
      "(310, 14) (310, 1)\n",
      "step=33500, loss=-971949120.00\n",
      "(310, 14) (310, 1)\n",
      "step=33600, loss=-1264140032.00\n",
      "(310, 14) (310, 1)\n",
      "step=33700, loss=-1367724672.00\n",
      "(310, 14) (310, 1)\n",
      "step=33800, loss=-1759382912.00\n",
      "(310, 14) (310, 1)\n",
      "step=33900, loss=-1859922304.00\n",
      "(310, 14) (310, 1)\n",
      "step=34000, loss=-1865409792.00\n",
      "(310, 14) (310, 1)\n",
      "step=34100, loss=-1283377280.00\n",
      "(310, 14) (310, 1)\n",
      "step=34200, loss=-1780137984.00\n",
      "(310, 14) (310, 1)\n",
      "step=34300, loss=-1882071552.00\n",
      "(310, 14) (310, 1)\n",
      "step=34400, loss=-1294670592.00\n",
      "(310, 14) (310, 1)\n",
      "step=34500, loss=-1400660736.00\n",
      "(310, 14) (310, 1)\n",
      "step=34600, loss=-1899044352.00\n",
      "(310, 14) (310, 1)\n",
      "step=34700, loss=-1408540928.00\n",
      "(310, 14) (310, 1)\n",
      "step=34800, loss=-603436224.00\n",
      "(310, 14) (310, 1)\n",
      "step=34900, loss=-1313346176.00\n",
      "(310, 14) (310, 1)\n",
      "step=35000, loss=-1420977152.00\n",
      "(310, 14) (310, 1)\n",
      "step=35100, loss=-1018753088.00\n",
      "(310, 14) (310, 1)\n",
      "step=35200, loss=-610425600.00\n",
      "(310, 14) (310, 1)\n",
      "step=35300, loss=-1120363520.00\n",
      "(310, 14) (310, 1)\n",
      "step=35400, loss=-1943156608.00\n",
      "(310, 14) (310, 1)\n",
      "step=35500, loss=-1336429952.00\n",
      "(310, 14) (310, 1)\n",
      "step=35600, loss=-1954314752.00\n",
      "(310, 14) (310, 1)\n",
      "step=35700, loss=-1859200512.00\n",
      "(310, 14) (310, 1)\n",
      "step=35800, loss=-1347646848.00\n",
      "(310, 14) (310, 1)\n",
      "step=35900, loss=-1970607232.00\n",
      "(310, 14) (310, 1)\n",
      "step=36000, loss=-624295296.00\n",
      "(310, 14) (310, 1)\n",
      "step=36100, loss=-1465480448.00\n",
      "(310, 14) (310, 1)\n",
      "step=36200, loss=-1986934272.00\n",
      "(310, 14) (310, 1)\n",
      "step=36300, loss=-629452928.00\n",
      "(310, 14) (310, 1)\n",
      "step=36400, loss=-1477646848.00\n",
      "(310, 14) (310, 1)\n",
      "step=36500, loss=-1481475840.00\n",
      "(310, 14) (310, 1)\n",
      "step=36600, loss=-1485291904.00\n",
      "(310, 14) (310, 1)\n",
      "step=36700, loss=-2013549952.00\n",
      "(310, 14) (310, 1)\n",
      "step=36800, loss=-1493176704.00\n",
      "(310, 14) (310, 1)\n",
      "step=36900, loss=-1170501376.00\n",
      "(310, 14) (310, 1)\n",
      "step=37000, loss=-1073529088.00\n",
      "(310, 14) (310, 1)\n",
      "step=37100, loss=-1177095680.00\n",
      "(310, 14) (310, 1)\n",
      "step=37200, loss=-1180402688.00\n",
      "(310, 14) (310, 1)\n",
      "step=37300, loss=-1403995392.00\n",
      "(310, 14) (310, 1)\n",
      "step=37400, loss=-1407453824.00\n",
      "(310, 14) (310, 1)\n",
      "step=37500, loss=-1088450560.00\n",
      "(310, 14) (310, 1)\n",
      "step=37600, loss=-1193173376.00\n",
      "(310, 14) (310, 1)\n",
      "step=37700, loss=-1962823040.00\n",
      "(310, 14) (310, 1)\n",
      "step=37800, loss=-655495808.00\n",
      "(310, 14) (310, 1)\n",
      "step=37900, loss=-657134336.00\n",
      "(310, 14) (310, 1)\n",
      "step=38000, loss=-1430363136.00\n",
      "(310, 14) (310, 1)\n",
      "step=38100, loss=-1434160000.00\n",
      "(310, 14) (310, 1)\n",
      "step=38200, loss=-1871264896.00\n",
      "(310, 14) (310, 1)\n",
      "step=38300, loss=-1993891584.00\n",
      "(310, 14) (310, 1)\n",
      "step=38400, loss=-1445220352.00\n",
      "(310, 14) (310, 1)\n",
      "step=38500, loss=-1117407104.00\n",
      "(310, 14) (310, 1)\n",
      "step=38600, loss=-2118788352.00\n",
      "(310, 14) (310, 1)\n",
      "step=38700, loss=-1456576640.00\n",
      "(310, 14) (310, 1)\n",
      "step=38800, loss=-1575406080.00\n",
      "(310, 14) (310, 1)\n",
      "step=38900, loss=-1464603136.00\n",
      "(310, 14) (310, 1)\n",
      "step=39000, loss=-2030910208.00\n",
      "(310, 14) (310, 1)\n",
      "step=39100, loss=-1472238720.00\n",
      "(310, 14) (310, 1)\n",
      "step=39200, loss=-1138069632.00\n",
      "(310, 14) (310, 1)\n",
      "step=39300, loss=-1926223104.00\n",
      "(310, 14) (310, 1)\n",
      "step=39400, loss=-1250907008.00\n",
      "(310, 14) (310, 1)\n",
      "step=39500, loss=-2168711680.00\n",
      "(310, 14) (310, 1)\n",
      "step=39600, loss=-1491262848.00\n",
      "(310, 14) (310, 1)\n",
      "step=39700, loss=-1612323456.00\n",
      "(310, 14) (310, 1)\n",
      "step=39800, loss=-1616347392.00\n",
      "(310, 14) (310, 1)\n",
      "step=39900, loss=-1620356992.00\n",
      "(310, 14) (310, 1)\n",
      "step=40000, loss=-1624229248.00\n",
      "(310, 14) (310, 1)\n",
      "step=40100, loss=-1509771904.00\n",
      "(310, 14) (310, 1)\n",
      "step=40200, loss=-2093121024.00\n",
      "(310, 14) (310, 1)\n",
      "step=40300, loss=-1517060480.00\n",
      "(310, 14) (310, 1)\n",
      "step=40400, loss=-1979573376.00\n",
      "(310, 14) (310, 1)\n",
      "step=40500, loss=-1984250880.00\n",
      "(310, 14) (310, 1)\n",
      "step=40600, loss=-1989561216.00\n",
      "(310, 14) (310, 1)\n",
      "step=40700, loss=-2119607296.00\n",
      "(310, 14) (310, 1)\n",
      "step=40800, loss=-707703168.00\n",
      "(310, 14) (310, 1)\n",
      "step=40900, loss=-1187294208.00\n",
      "(310, 14) (310, 1)\n",
      "step=41000, loss=-2009184000.00\n",
      "(310, 14) (310, 1)\n",
      "step=41100, loss=-712816064.00\n",
      "(310, 14) (310, 1)\n",
      "step=41200, loss=-1672455552.00\n",
      "(310, 14) (310, 1)\n",
      "step=41300, loss=-2267002880.00\n",
      "(310, 14) (310, 1)\n",
      "step=41400, loss=-1680854656.00\n",
      "(310, 14) (310, 1)\n",
      "step=41500, loss=-2033392384.00\n",
      "(310, 14) (310, 1)\n",
      "step=41600, loss=-721475136.00\n",
      "(310, 14) (310, 1)\n",
      "step=41700, loss=-1570045184.00\n",
      "(310, 14) (310, 1)\n",
      "step=41800, loss=-1573837952.00\n",
      "(310, 14) (310, 1)\n",
      "step=41900, loss=-2181834496.00\n",
      "(310, 14) (310, 1)\n",
      "step=42000, loss=-728380864.00\n",
      "(310, 14) (310, 1)\n",
      "step=42100, loss=-729990720.00\n",
      "(310, 14) (310, 1)\n",
      "step=42200, loss=-1339074048.00\n",
      "(310, 14) (310, 1)\n",
      "step=42300, loss=-733465856.00\n",
      "(310, 14) (310, 1)\n",
      "step=42400, loss=-1230483200.00\n",
      "(310, 14) (310, 1)\n",
      "step=42500, loss=-1725358080.00\n",
      "(310, 14) (310, 1)\n",
      "step=42600, loss=-1236331648.00\n",
      "(310, 14) (310, 1)\n",
      "step=42700, loss=-1355029120.00\n",
      "(310, 14) (310, 1)\n",
      "step=42800, loss=-1737273216.00\n",
      "(310, 14) (310, 1)\n",
      "step=42900, loss=-743757504.00\n",
      "(310, 14) (310, 1)\n",
      "step=43000, loss=-745552704.00\n",
      "(310, 14) (310, 1)\n",
      "step=43100, loss=-2243499520.00\n",
      "(310, 14) (310, 1)\n",
      "step=43200, loss=-748941760.00\n",
      "(310, 14) (310, 1)\n",
      "step=43300, loss=-1757458048.00\n",
      "(310, 14) (310, 1)\n",
      "step=43400, loss=-1376940800.00\n",
      "(310, 14) (310, 1)\n",
      "step=43500, loss=-1637082112.00\n",
      "(310, 14) (310, 1)\n",
      "step=43600, loss=-1769640960.00\n",
      "(310, 14) (310, 1)\n",
      "step=43700, loss=-1773517568.00\n",
      "(310, 14) (310, 1)\n",
      "step=43800, loss=-1389863808.00\n",
      "(310, 14) (310, 1)\n",
      "step=43900, loss=-2285711104.00\n",
      "(310, 14) (310, 1)\n",
      "step=44000, loss=-2415281408.00\n",
      "(310, 14) (310, 1)\n",
      "step=44100, loss=-1660529152.00\n",
      "(310, 14) (310, 1)\n",
      "step=44200, loss=-1664082048.00\n",
      "(310, 14) (310, 1)\n",
      "step=44300, loss=-2170679040.00\n",
      "(310, 14) (310, 1)\n",
      "step=44400, loss=-1802717696.00\n",
      "(310, 14) (310, 1)\n",
      "step=44500, loss=-2316960768.00\n",
      "(310, 14) (310, 1)\n",
      "step=44600, loss=-1415282944.00\n",
      "(310, 14) (310, 1)\n",
      "step=44700, loss=-2326909440.00\n",
      "(310, 14) (310, 1)\n",
      "step=44800, loss=-1686347392.00\n",
      "(310, 14) (310, 1)\n",
      "step=44900, loss=-2337312512.00\n",
      "(310, 14) (310, 1)\n",
      "step=45000, loss=-1826664960.00\n",
      "(310, 14) (310, 1)\n",
      "step=45100, loss=-1697460864.00\n",
      "(310, 14) (310, 1)\n",
      "step=45200, loss=-2352846080.00\n",
      "(310, 14) (310, 1)\n",
      "step=45300, loss=-1314360960.00\n",
      "(310, 14) (310, 1)\n",
      "step=45400, loss=-1708276992.00\n",
      "(310, 14) (310, 1)\n",
      "step=45500, loss=-1443537920.00\n",
      "(310, 14) (310, 1)\n",
      "step=45600, loss=-1850815488.00\n",
      "(310, 14) (310, 1)\n",
      "step=45700, loss=-1719493376.00\n",
      "(310, 14) (310, 1)\n",
      "step=45800, loss=-1723329792.00\n",
      "(310, 14) (310, 1)\n",
      "step=45900, loss=-1863055616.00\n",
      "(310, 14) (310, 1)\n",
      "step=46000, loss=-1866811648.00\n",
      "(310, 14) (310, 1)\n",
      "step=46100, loss=-1337536128.00\n",
      "(310, 14) (310, 1)\n",
      "step=46200, loss=-1875041024.00\n",
      "(310, 14) (310, 1)\n",
      "step=46300, loss=-802687168.00\n",
      "(310, 14) (310, 1)\n",
      "step=46400, loss=-804474816.00\n",
      "(310, 14) (310, 1)\n",
      "step=46500, loss=-1349328128.00\n",
      "(310, 14) (310, 1)\n",
      "step=46600, loss=-1891607552.00\n",
      "(310, 14) (310, 1)\n",
      "step=46700, loss=-1481737088.00\n",
      "(310, 14) (310, 1)\n",
      "step=46800, loss=-1761054336.00\n",
      "(310, 14) (310, 1)\n",
      "step=46900, loss=-1487938432.00\n",
      "(310, 14) (310, 1)\n",
      "step=47000, loss=-2446497792.00\n",
      "(310, 14) (310, 1)\n",
      "step=47100, loss=-2584509440.00\n",
      "(310, 14) (310, 1)\n",
      "step=47200, loss=-1369591936.00\n",
      "(310, 14) (310, 1)\n",
      "step=47300, loss=-1919585280.00\n",
      "(310, 14) (310, 1)\n",
      "step=47400, loss=-1503738880.00\n",
      "(310, 14) (310, 1)\n",
      "step=47500, loss=-1787506304.00\n",
      "(310, 14) (310, 1)\n",
      "step=47600, loss=-1791387136.00\n",
      "(310, 14) (310, 1)\n",
      "step=47700, loss=-1795245056.00\n",
      "(310, 14) (310, 1)\n",
      "step=47800, loss=-1386989056.00\n",
      "(310, 14) (310, 1)\n",
      "step=47900, loss=-1802988416.00\n",
      "(310, 14) (310, 1)\n",
      "step=48000, loss=-1948646912.00\n",
      "(310, 14) (310, 1)\n",
      "step=48100, loss=-1810723456.00\n",
      "(310, 14) (310, 1)\n",
      "step=48200, loss=-1814093696.00\n",
      "(310, 14) (310, 1)\n",
      "step=48300, loss=-1960936576.00\n",
      "(310, 14) (310, 1)\n",
      "step=48400, loss=-1536038016.00\n",
      "(310, 14) (310, 1)\n",
      "step=48500, loss=-1825381248.00\n",
      "(310, 14) (310, 1)\n",
      "step=48600, loss=-1410441600.00\n",
      "(310, 14) (310, 1)\n",
      "step=48700, loss=-844486208.00\n",
      "(310, 14) (310, 1)\n",
      "step=48800, loss=-1548442752.00\n",
      "(310, 14) (310, 1)\n",
      "step=48900, loss=-2683734272.00\n",
      "(310, 14) (310, 1)\n",
      "step=49000, loss=-1422103424.00\n",
      "(310, 14) (310, 1)\n",
      "step=49100, loss=-1993326720.00\n",
      "(310, 14) (310, 1)\n",
      "step=49200, loss=-2410370304.00\n",
      "(310, 14) (310, 1)\n",
      "step=49300, loss=-2001021568.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=49400, loss=-1859190528.00\n",
      "(310, 14) (310, 1)\n",
      "step=49500, loss=-1863056896.00\n",
      "(310, 14) (310, 1)\n",
      "step=49600, loss=-2722102272.00\n",
      "(310, 14) (310, 1)\n",
      "step=49700, loss=-2017595008.00\n",
      "(310, 14) (310, 1)\n",
      "step=49800, loss=-1874165376.00\n",
      "(310, 14) (310, 1)\n",
      "step=49900, loss=-2026052608.00\n",
      "(310, 14) (310, 1)\n",
      "step=50000, loss=-2744231424.00\n",
      "(310, 14) (310, 1)\n",
      "step=50100, loss=-2033708928.00\n",
      "(310, 14) (310, 1)\n",
      "step=50200, loss=-2038072832.00\n",
      "(310, 14) (310, 1)\n",
      "step=50300, loss=-1596241024.00\n",
      "(310, 14) (310, 1)\n",
      "step=50400, loss=-873977152.00\n",
      "(310, 14) (310, 1)\n",
      "step=50500, loss=-1602462848.00\n",
      "(310, 14) (310, 1)\n",
      "step=50600, loss=-1605815936.00\n",
      "(310, 14) (310, 1)\n",
      "step=50700, loss=-879262016.00\n",
      "(310, 14) (310, 1)\n",
      "step=50800, loss=-1474552832.00\n",
      "(310, 14) (310, 1)\n",
      "step=50900, loss=-2650242304.00\n",
      "(310, 14) (310, 1)\n",
      "step=51000, loss=-2498787072.00\n",
      "(310, 14) (310, 1)\n",
      "step=51100, loss=-886241984.00\n",
      "(310, 14) (310, 1)\n",
      "step=51200, loss=-2078823296.00\n",
      "(310, 14) (310, 1)\n",
      "step=51300, loss=-2082708480.00\n",
      "(310, 14) (310, 1)\n",
      "step=51400, loss=-2087085568.00\n",
      "(310, 14) (310, 1)\n",
      "step=51500, loss=-2827193344.00\n",
      "(310, 14) (310, 1)\n",
      "step=51600, loss=-1943030912.00\n",
      "(310, 14) (310, 1)\n",
      "step=51700, loss=-2533664256.00\n",
      "(310, 14) (310, 1)\n",
      "step=51800, loss=-2697537792.00\n",
      "(310, 14) (310, 1)\n",
      "step=51900, loss=-2107598464.00\n",
      "(310, 14) (310, 1)\n",
      "step=52000, loss=-1509622144.00\n",
      "(310, 14) (310, 1)\n",
      "step=52100, loss=-2115744000.00\n",
      "(310, 14) (310, 1)\n",
      "step=52200, loss=-2119476480.00\n",
      "(310, 14) (310, 1)\n",
      "step=52300, loss=-907182080.00\n",
      "(310, 14) (310, 1)\n",
      "step=52400, loss=-1972649600.00\n",
      "(310, 14) (310, 1)\n",
      "step=52500, loss=-2734337792.00\n",
      "(310, 14) (310, 1)\n",
      "step=52600, loss=-1980763264.00\n",
      "(310, 14) (310, 1)\n",
      "step=52700, loss=-1983974400.00\n",
      "(310, 14) (310, 1)\n",
      "step=52800, loss=-1676122752.00\n",
      "(310, 14) (310, 1)\n",
      "step=52900, loss=-1991760128.00\n",
      "(310, 14) (310, 1)\n",
      "step=53000, loss=-2597844992.00\n",
      "(310, 14) (310, 1)\n",
      "step=53100, loss=-2156761600.00\n",
      "(310, 14) (310, 1)\n",
      "step=53200, loss=-2607854336.00\n",
      "(310, 14) (310, 1)\n",
      "step=53300, loss=-2007161856.00\n",
      "(310, 14) (310, 1)\n",
      "step=53400, loss=-1550734720.00\n",
      "(310, 14) (310, 1)\n",
      "step=53500, loss=-1698777984.00\n",
      "(310, 14) (310, 1)\n",
      "step=53600, loss=-2792337152.00\n",
      "(310, 14) (310, 1)\n",
      "step=53700, loss=-2022341760.00\n",
      "(310, 14) (310, 1)\n",
      "step=53800, loss=-2637290240.00\n",
      "(310, 14) (310, 1)\n",
      "step=53900, loss=-1565189632.00\n",
      "(310, 14) (310, 1)\n",
      "step=54000, loss=-936857856.00\n",
      "(310, 14) (310, 1)\n",
      "step=54100, loss=-2651720704.00\n",
      "(310, 14) (310, 1)\n",
      "step=54200, loss=-940281920.00\n",
      "(310, 14) (310, 1)\n",
      "step=54300, loss=-2981725696.00\n",
      "(310, 14) (310, 1)\n",
      "step=54400, loss=-2209802496.00\n",
      "(310, 14) (310, 1)\n",
      "step=54500, loss=-2213517312.00\n",
      "(310, 14) (310, 1)\n",
      "step=54600, loss=-2056143616.00\n",
      "(310, 14) (310, 1)\n",
      "step=54700, loss=-1736905600.00\n",
      "(310, 14) (310, 1)\n",
      "step=54800, loss=-3009306880.00\n",
      "(310, 14) (310, 1)\n",
      "step=54900, loss=-2229970432.00\n",
      "(310, 14) (310, 1)\n",
      "step=55000, loss=-954306112.00\n",
      "(310, 14) (310, 1)\n",
      "step=55100, loss=-2075434880.00\n",
      "(310, 14) (310, 1)\n",
      "step=55200, loss=-1752815872.00\n",
      "(310, 14) (310, 1)\n",
      "step=55300, loss=-2880913664.00\n",
      "(310, 14) (310, 1)\n",
      "step=55400, loss=-2086658176.00\n",
      "(310, 14) (310, 1)\n",
      "step=55500, loss=-962993024.00\n",
      "(310, 14) (310, 1)\n",
      "step=55600, loss=-2896583168.00\n",
      "(310, 14) (310, 1)\n",
      "step=55700, loss=-1617622912.00\n",
      "(310, 14) (310, 1)\n",
      "step=55800, loss=-3064540928.00\n",
      "(310, 14) (310, 1)\n",
      "step=55900, loss=-2104989568.00\n",
      "(310, 14) (310, 1)\n",
      "step=56000, loss=-2109351808.00\n",
      "(310, 14) (310, 1)\n",
      "step=56100, loss=-1781278848.00\n",
      "(310, 14) (310, 1)\n",
      "step=56200, loss=-3086231296.00\n",
      "(310, 14) (310, 1)\n",
      "step=56300, loss=-1787651328.00\n",
      "(310, 14) (310, 1)\n",
      "step=56400, loss=-1637712256.00\n",
      "(310, 14) (310, 1)\n",
      "step=56500, loss=-2769683968.00\n",
      "(310, 14) (310, 1)\n",
      "step=56600, loss=-1643514496.00\n",
      "(310, 14) (310, 1)\n",
      "step=56700, loss=-3113516800.00\n",
      "(310, 14) (310, 1)\n",
      "step=56800, loss=-2784290304.00\n",
      "(310, 14) (310, 1)\n",
      "step=56900, loss=-2964012032.00\n",
      "(310, 14) (310, 1)\n",
      "step=57000, loss=-2315151104.00\n",
      "(310, 14) (310, 1)\n",
      "step=57100, loss=-2318879232.00\n",
      "(310, 14) (310, 1)\n",
      "step=57200, loss=-2323528192.00\n",
      "(310, 14) (310, 1)\n",
      "step=57300, loss=-2809031168.00\n",
      "(310, 14) (310, 1)\n",
      "step=57400, loss=-2161607936.00\n",
      "(310, 14) (310, 1)\n",
      "step=57500, loss=-2335386880.00\n",
      "(310, 14) (310, 1)\n",
      "step=57600, loss=-3163127808.00\n",
      "(310, 14) (310, 1)\n",
      "step=57700, loss=-2343942144.00\n",
      "(310, 14) (310, 1)\n",
      "step=57800, loss=-3174124800.00\n",
      "(310, 14) (310, 1)\n",
      "step=57900, loss=-2180299520.00\n",
      "(310, 14) (310, 1)\n",
      "step=58000, loss=-1684270720.00\n",
      "(310, 14) (310, 1)\n",
      "step=58100, loss=-1008027200.00\n",
      "(310, 14) (310, 1)\n",
      "step=58200, loss=-3031712768.00\n",
      "(310, 14) (310, 1)\n",
      "step=58300, loss=-1692871168.00\n",
      "(310, 14) (310, 1)\n",
      "step=58400, loss=-2198924032.00\n",
      "(310, 14) (310, 1)\n",
      "step=58500, loss=-1857486848.00\n",
      "(310, 14) (310, 1)\n",
      "step=58600, loss=-2380486656.00\n",
      "(310, 14) (310, 1)\n",
      "step=58700, loss=-3224028928.00\n",
      "(310, 14) (310, 1)\n",
      "step=58800, loss=-2214427136.00\n",
      "(310, 14) (310, 1)\n",
      "step=58900, loss=-2887632896.00\n",
      "(310, 14) (310, 1)\n",
      "step=59000, loss=-2892515840.00\n",
      "(310, 14) (310, 1)\n",
      "step=59100, loss=-2225722368.00\n",
      "(310, 14) (310, 1)\n",
      "step=59200, loss=-2229681408.00\n",
      "(310, 14) (310, 1)\n",
      "step=59300, loss=-2907534336.00\n",
      "(310, 14) (310, 1)\n",
      "step=59400, loss=-1030825024.00\n",
      "(310, 14) (310, 1)\n",
      "step=59500, loss=-1728183936.00\n",
      "(310, 14) (310, 1)\n",
      "step=59600, loss=-2244828416.00\n",
      "(310, 14) (310, 1)\n",
      "step=59700, loss=-3110538496.00\n",
      "(310, 14) (310, 1)\n",
      "step=59800, loss=-1899083136.00\n",
      "(310, 14) (310, 1)\n",
      "step=59900, loss=-2937146112.00\n",
      "(310, 14) (310, 1)\n",
      "step=60000, loss=-3126664960.00\n",
      "(310, 14) (310, 1)\n",
      "step=60100, loss=-1043165952.00\n",
      "(310, 14) (310, 1)\n",
      "step=60200, loss=-3137300736.00\n",
      "(310, 14) (310, 1)\n",
      "step=60300, loss=-1046571712.00\n",
      "(310, 14) (310, 1)\n",
      "step=60400, loss=-2453922048.00\n",
      "(310, 14) (310, 1)\n",
      "step=60500, loss=-2458528768.00\n",
      "(310, 14) (310, 1)\n",
      "step=60600, loss=-1924944512.00\n",
      "(310, 14) (310, 1)\n",
      "step=60700, loss=-3163350016.00\n",
      "(310, 14) (310, 1)\n",
      "step=60800, loss=-1055319104.00\n",
      "(310, 14) (310, 1)\n",
      "step=60900, loss=-1769117312.00\n",
      "(310, 14) (310, 1)\n",
      "step=61000, loss=-2298086656.00\n",
      "(310, 14) (310, 1)\n",
      "step=61100, loss=-2302517504.00\n",
      "(310, 14) (310, 1)\n",
      "step=61200, loss=-3362458368.00\n",
      "(310, 14) (310, 1)\n",
      "step=61300, loss=-2490845184.00\n",
      "(310, 14) (310, 1)\n",
      "step=61400, loss=-2313781760.00\n",
      "(310, 14) (310, 1)\n",
      "step=61500, loss=-1786763136.00\n",
      "(310, 14) (310, 1)\n",
      "step=61600, loss=-3021336320.00\n",
      "(310, 14) (310, 1)\n",
      "step=61700, loss=-3026066944.00\n",
      "(310, 14) (310, 1)\n",
      "step=61800, loss=-1963159936.00\n",
      "(310, 14) (310, 1)\n",
      "step=61900, loss=-2332334336.00\n",
      "(310, 14) (310, 1)\n",
      "step=62000, loss=-2335397376.00\n",
      "(310, 14) (310, 1)\n",
      "step=62100, loss=-2523378176.00\n",
      "(310, 14) (310, 1)\n",
      "step=62200, loss=-2343323392.00\n",
      "(310, 14) (310, 1)\n",
      "step=62300, loss=-1978478208.00\n",
      "(310, 14) (310, 1)\n",
      "step=62400, loss=-1082808064.00\n",
      "(310, 14) (310, 1)\n",
      "step=62500, loss=-2353783040.00\n",
      "(310, 14) (310, 1)\n",
      "step=62600, loss=-2357452544.00\n",
      "(310, 14) (310, 1)\n",
      "step=62700, loss=-2361727488.00\n",
      "(310, 14) (310, 1)\n",
      "step=62800, loss=-2550670336.00\n",
      "(310, 14) (310, 1)\n",
      "step=62900, loss=-1091279744.00\n",
      "(310, 14) (310, 1)\n",
      "step=63000, loss=-2000135424.00\n",
      "(310, 14) (310, 1)\n",
      "step=63100, loss=-2562741504.00\n",
      "(310, 14) (310, 1)\n",
      "step=63200, loss=-2566847232.00\n",
      "(310, 14) (310, 1)\n",
      "step=63300, loss=-3296933376.00\n",
      "(310, 14) (310, 1)\n",
      "step=63400, loss=-2387548672.00\n",
      "(310, 14) (310, 1)\n",
      "step=63500, loss=-3307418112.00\n",
      "(310, 14) (310, 1)\n",
      "step=63600, loss=-2394499840.00\n",
      "(310, 14) (310, 1)\n",
      "step=63700, loss=-3121960448.00\n",
      "(310, 14) (310, 1)\n",
      "step=63800, loss=-3322943232.00\n",
      "(310, 14) (310, 1)\n",
      "step=63900, loss=-1855104512.00\n",
      "(310, 14) (310, 1)\n",
      "step=64000, loss=-2410027520.00\n",
      "(310, 14) (310, 1)\n",
      "step=64100, loss=-1111856256.00\n",
      "(310, 14) (310, 1)\n",
      "step=64200, loss=-2037959296.00\n",
      "(310, 14) (310, 1)\n",
      "step=64300, loss=-1115324160.00\n",
      "(310, 14) (310, 1)\n",
      "step=64400, loss=-2614878720.00\n",
      "(310, 14) (310, 1)\n",
      "step=64500, loss=-2428156160.00\n",
      "(310, 14) (310, 1)\n",
      "step=64600, loss=-3165815296.00\n",
      "(310, 14) (310, 1)\n",
      "step=64700, loss=-2627070464.00\n",
      "(310, 14) (310, 1)\n",
      "step=64800, loss=-1881226368.00\n",
      "(310, 14) (310, 1)\n",
      "step=64900, loss=-3180630272.00\n",
      "(310, 14) (310, 1)\n",
      "step=65000, loss=-2639508224.00\n",
      "(310, 14) (310, 1)\n",
      "step=65100, loss=-2643210752.00\n",
      "(310, 14) (310, 1)\n",
      "step=65200, loss=-1892613120.00\n",
      "(310, 14) (310, 1)\n",
      "step=65300, loss=-2072663936.00\n",
      "(310, 14) (310, 1)\n",
      "step=65400, loss=-1134319232.00\n",
      "(310, 14) (310, 1)\n",
      "step=65500, loss=-2079047040.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=65600, loss=-3214678272.00\n",
      "(310, 14) (310, 1)\n",
      "step=65700, loss=-3219640832.00\n",
      "(310, 14) (310, 1)\n",
      "step=65800, loss=-1141250688.00\n",
      "(310, 14) (310, 1)\n",
      "step=65900, loss=-2091679232.00\n",
      "(310, 14) (310, 1)\n",
      "step=66000, loss=-3623249920.00\n",
      "(310, 14) (310, 1)\n",
      "step=66100, loss=-1918794496.00\n",
      "(310, 14) (310, 1)\n",
      "step=66200, loss=-1921681152.00\n",
      "(310, 14) (310, 1)\n",
      "step=66300, loss=-3248822528.00\n",
      "(310, 14) (310, 1)\n",
      "step=66400, loss=-2107542272.00\n",
      "(310, 14) (310, 1)\n",
      "step=66500, loss=-2503311104.00\n",
      "(310, 14) (310, 1)\n",
      "step=66600, loss=-2507756032.00\n",
      "(310, 14) (310, 1)\n",
      "step=66700, loss=-2708594944.00\n",
      "(310, 14) (310, 1)\n",
      "step=66800, loss=-2514649856.00\n",
      "(310, 14) (310, 1)\n",
      "step=66900, loss=-2123446528.00\n",
      "(310, 14) (310, 1)\n",
      "step=67000, loss=-2126523392.00\n",
      "(310, 14) (310, 1)\n",
      "step=67100, loss=-1163713664.00\n",
      "(310, 14) (310, 1)\n",
      "step=67200, loss=-2728203008.00\n",
      "(310, 14) (310, 1)\n",
      "step=67300, loss=-3297685248.00\n",
      "(310, 14) (310, 1)\n",
      "step=67400, loss=-1956300288.00\n",
      "(310, 14) (310, 1)\n",
      "step=67500, loss=-2740114176.00\n",
      "(310, 14) (310, 1)\n",
      "step=67600, loss=-3710386944.00\n",
      "(310, 14) (310, 1)\n",
      "step=67700, loss=-1964929408.00\n",
      "(310, 14) (310, 1)\n",
      "step=67800, loss=-2752092416.00\n",
      "(310, 14) (310, 1)\n",
      "step=67900, loss=-2555385856.00\n",
      "(310, 14) (310, 1)\n",
      "step=68000, loss=-2760074496.00\n",
      "(310, 14) (310, 1)\n",
      "step=68100, loss=-2764124416.00\n",
      "(310, 14) (310, 1)\n",
      "step=68200, loss=-3550595584.00\n",
      "(310, 14) (310, 1)\n",
      "step=68300, loss=-2570370304.00\n",
      "(310, 14) (310, 1)\n",
      "step=68400, loss=-2776864000.00\n",
      "(310, 14) (310, 1)\n",
      "step=68500, loss=-2173662720.00\n",
      "(310, 14) (310, 1)\n",
      "step=68600, loss=-2582346496.00\n",
      "(310, 14) (310, 1)\n",
      "step=68700, loss=-3770527488.00\n",
      "(310, 14) (310, 1)\n",
      "step=68800, loss=-2589360896.00\n",
      "(310, 14) (310, 1)\n",
      "step=68900, loss=-3781819392.00\n",
      "(310, 14) (310, 1)\n",
      "step=69000, loss=-3380794880.00\n",
      "(310, 14) (310, 1)\n",
      "step=69100, loss=-2601236992.00\n",
      "(310, 14) (310, 1)\n",
      "step=69200, loss=-3797903104.00\n",
      "(310, 14) (310, 1)\n",
      "step=69300, loss=-2813573376.00\n",
      "(310, 14) (310, 1)\n",
      "step=69400, loss=-3613273856.00\n",
      "(310, 14) (310, 1)\n",
      "step=69500, loss=-2616212992.00\n",
      "(310, 14) (310, 1)\n",
      "step=69600, loss=-2825530624.00\n",
      "(310, 14) (310, 1)\n",
      "step=69700, loss=-3628867328.00\n",
      "(310, 14) (310, 1)\n",
      "step=69800, loss=-2626944512.00\n",
      "(310, 14) (310, 1)\n",
      "step=69900, loss=-3638989568.00\n",
      "(310, 14) (310, 1)\n",
      "step=70000, loss=-3429241856.00\n",
      "(310, 14) (310, 1)\n",
      "step=70100, loss=-2845158656.00\n",
      "(310, 14) (310, 1)\n",
      "step=70200, loss=-2849420800.00\n",
      "(310, 14) (310, 1)\n",
      "step=70300, loss=-2645845248.00\n",
      "(310, 14) (310, 1)\n",
      "step=70400, loss=-2042728960.00\n",
      "(310, 14) (310, 1)\n",
      "step=70500, loss=-2236893952.00\n",
      "(310, 14) (310, 1)\n",
      "step=70600, loss=-2657250560.00\n",
      "(310, 14) (310, 1)\n",
      "step=70700, loss=-2660692480.00\n",
      "(310, 14) (310, 1)\n",
      "step=70800, loss=-2663853824.00\n",
      "(310, 14) (310, 1)\n",
      "step=70900, loss=-2057168384.00\n",
      "(310, 14) (310, 1)\n",
      "step=71000, loss=-2252712704.00\n",
      "(310, 14) (310, 1)\n",
      "step=71100, loss=-2676171264.00\n",
      "(310, 14) (310, 1)\n",
      "step=71200, loss=-2065949184.00\n",
      "(310, 14) (310, 1)\n",
      "step=71300, loss=-3711400448.00\n",
      "(310, 14) (310, 1)\n",
      "step=71400, loss=-3497556992.00\n",
      "(310, 14) (310, 1)\n",
      "step=71500, loss=-2690398976.00\n",
      "(310, 14) (310, 1)\n",
      "step=71600, loss=-1241293312.00\n",
      "(310, 14) (310, 1)\n",
      "step=71700, loss=-3934591232.00\n",
      "(310, 14) (310, 1)\n",
      "step=71800, loss=-3516981504.00\n",
      "(310, 14) (310, 1)\n",
      "step=71900, loss=-2281309952.00\n",
      "(310, 14) (310, 1)\n",
      "step=72000, loss=-2922221824.00\n",
      "(310, 14) (310, 1)\n",
      "step=72100, loss=-3956729600.00\n",
      "(310, 14) (310, 1)\n",
      "step=72200, loss=-3758674688.00\n",
      "(310, 14) (310, 1)\n",
      "step=72300, loss=-1253640576.00\n",
      "(310, 14) (310, 1)\n",
      "step=72400, loss=-2938540544.00\n",
      "(310, 14) (310, 1)\n",
      "step=72500, loss=-3774488320.00\n",
      "(310, 14) (310, 1)\n",
      "step=72600, loss=-3984824320.00\n",
      "(310, 14) (310, 1)\n",
      "step=72700, loss=-3785241600.00\n",
      "(310, 14) (310, 1)\n",
      "step=72800, loss=-2310364416.00\n",
      "(310, 14) (310, 1)\n",
      "step=72900, loss=-3571960320.00\n",
      "(310, 14) (310, 1)\n",
      "step=73000, loss=-2316754688.00\n",
      "(310, 14) (310, 1)\n",
      "step=73100, loss=-3806022144.00\n",
      "(310, 14) (310, 1)\n",
      "step=73200, loss=-4017500672.00\n",
      "(310, 14) (310, 1)\n",
      "step=73300, loss=-2975283712.00\n",
      "(310, 14) (310, 1)\n",
      "step=73400, loss=-3821478144.00\n",
      "(310, 14) (310, 1)\n",
      "step=73500, loss=-2983926784.00\n",
      "(310, 14) (310, 1)\n",
      "step=73600, loss=-2987906048.00\n",
      "(310, 14) (310, 1)\n",
      "step=73700, loss=-3610558720.00\n",
      "(310, 14) (310, 1)\n",
      "step=73800, loss=-1279633920.00\n",
      "(310, 14) (310, 1)\n",
      "step=73900, loss=-1281313664.00\n",
      "(310, 14) (310, 1)\n",
      "step=74000, loss=-3852355328.00\n",
      "(310, 14) (310, 1)\n",
      "step=74100, loss=-2788889600.00\n",
      "(310, 14) (310, 1)\n",
      "step=74200, loss=-3011872768.00\n",
      "(310, 14) (310, 1)\n",
      "step=74300, loss=-2796591104.00\n",
      "(310, 14) (310, 1)\n",
      "step=74400, loss=-2799672064.00\n",
      "(310, 14) (310, 1)\n",
      "step=74500, loss=-4088407296.00\n",
      "(310, 14) (310, 1)\n",
      "step=74600, loss=-3028438272.00\n",
      "(310, 14) (310, 1)\n",
      "step=74700, loss=-1295241600.00\n",
      "(310, 14) (310, 1)\n",
      "step=74800, loss=-3036675328.00\n",
      "(310, 14) (310, 1)\n",
      "step=74900, loss=-1298791296.00\n",
      "(310, 14) (310, 1)\n",
      "step=75000, loss=-3044817920.00\n",
      "(310, 14) (310, 1)\n",
      "step=75100, loss=-3679182080.00\n",
      "(310, 14) (310, 1)\n",
      "step=75200, loss=-1303979520.00\n",
      "(310, 14) (310, 1)\n",
      "step=75300, loss=-2389400832.00\n",
      "(310, 14) (310, 1)\n",
      "step=75400, loss=-4137757696.00\n",
      "(310, 14) (310, 1)\n",
      "step=75500, loss=-3698445568.00\n",
      "(310, 14) (310, 1)\n",
      "step=75600, loss=-3068603904.00\n",
      "(310, 14) (310, 1)\n",
      "step=75700, loss=-2196375808.00\n",
      "(310, 14) (310, 1)\n",
      "step=75800, loss=-1314045696.00\n",
      "(310, 14) (310, 1)\n",
      "step=75900, loss=-2407959040.00\n",
      "(310, 14) (310, 1)\n",
      "step=76000, loss=-3956269824.00\n",
      "(310, 14) (310, 1)\n",
      "step=76100, loss=-1319438464.00\n",
      "(310, 14) (310, 1)\n",
      "step=76200, loss=-3093157376.00\n",
      "(310, 14) (310, 1)\n",
      "step=76300, loss=-4187081472.00\n",
      "(310, 14) (310, 1)\n",
      "step=76400, loss=-2874840320.00\n",
      "(310, 14) (310, 1)\n",
      "step=76500, loss=-2878628096.00\n",
      "(310, 14) (310, 1)\n",
      "step=76600, loss=-3109373952.00\n",
      "(310, 14) (310, 1)\n",
      "step=76700, loss=-3113012224.00\n",
      "(310, 14) (310, 1)\n",
      "step=76800, loss=-2889908736.00\n",
      "(310, 14) (310, 1)\n",
      "step=76900, loss=-3120920064.00\n",
      "(310, 14) (310, 1)\n",
      "step=77000, loss=-3125195776.00\n",
      "(310, 14) (310, 1)\n",
      "step=77100, loss=-2237358848.00\n",
      "(310, 14) (310, 1)\n",
      "step=77200, loss=-2905737472.00\n",
      "(310, 14) (310, 1)\n",
      "step=77300, loss=-3137996544.00\n",
      "(310, 14) (310, 1)\n",
      "step=77400, loss=-2246195200.00\n",
      "(310, 14) (310, 1)\n",
      "step=77500, loss=-3146129152.00\n",
      "(310, 14) (310, 1)\n",
      "step=77600, loss=-3801652480.00\n",
      "(310, 14) (310, 1)\n",
      "step=77700, loss=-4264612864.00\n",
      "(310, 14) (310, 1)\n",
      "step=77800, loss=-3158638336.00\n",
      "(310, 14) (310, 1)\n",
      "step=77900, loss=-2260912384.00\n",
      "(310, 14) (310, 1)\n",
      "step=78000, loss=-2935584000.00\n",
      "(310, 14) (310, 1)\n",
      "step=78100, loss=-2939294208.00\n",
      "(310, 14) (310, 1)\n",
      "step=78200, loss=-2943666432.00\n",
      "(310, 14) (310, 1)\n",
      "step=78300, loss=-3178170624.00\n",
      "(310, 14) (310, 1)\n",
      "step=78400, loss=-2950448640.00\n",
      "(310, 14) (310, 1)\n",
      "step=78500, loss=-4086663424.00\n",
      "(310, 14) (310, 1)\n",
      "step=78600, loss=-3190180352.00\n",
      "(310, 14) (310, 1)\n",
      "step=78700, loss=-3855516160.00\n",
      "(310, 14) (310, 1)\n",
      "step=78800, loss=-2966205952.00\n",
      "(310, 14) (310, 1)\n",
      "step=78900, loss=-1368042240.00\n",
      "(310, 14) (310, 1)\n",
      "step=79000, loss=-3207105280.00\n",
      "(310, 14) (310, 1)\n",
      "step=79100, loss=-2509933056.00\n",
      "(310, 14) (310, 1)\n",
      "step=79200, loss=-2980929024.00\n",
      "(310, 14) (310, 1)\n",
      "step=79300, loss=-2301197824.00\n",
      "(310, 14) (310, 1)\n",
      "step=79400, loss=-3222687488.00\n",
      "(310, 14) (310, 1)\n",
      "step=79500, loss=-2992467456.00\n",
      "(310, 14) (310, 1)\n",
      "step=79600, loss=-4143769856.00\n",
      "(310, 14) (310, 1)\n",
      "step=79700, loss=-4373831168.00\n",
      "(310, 14) (310, 1)\n",
      "step=79800, loss=-3003679232.00\n",
      "(310, 14) (310, 1)\n",
      "step=79900, loss=-3007592448.00\n",
      "(310, 14) (310, 1)\n",
      "step=80000, loss=-3011332352.00\n",
      "(310, 14) (310, 1)\n",
      "step=80100, loss=-4169982976.00\n",
      "(310, 14) (310, 1)\n",
      "step=80200, loss=-2327441920.00\n",
      "(310, 14) (310, 1)\n",
      "step=80300, loss=-4180713472.00\n",
      "(310, 14) (310, 1)\n",
      "step=80400, loss=-2333299456.00\n",
      "(310, 14) (310, 1)\n",
      "step=80500, loss=-3030276864.00\n",
      "(310, 14) (310, 1)\n",
      "step=80600, loss=-3033430528.00\n",
      "(310, 14) (310, 1)\n",
      "step=80700, loss=-3037223168.00\n",
      "(310, 14) (310, 1)\n",
      "step=80800, loss=-3041019648.00\n",
      "(310, 14) (310, 1)\n",
      "step=80900, loss=-3044572928.00\n",
      "(310, 14) (310, 1)\n",
      "step=81000, loss=-3048337152.00\n",
      "(310, 14) (310, 1)\n",
      "step=81100, loss=-3973171200.00\n",
      "(310, 14) (310, 1)\n",
      "step=81200, loss=-2576767744.00\n",
      "(310, 14) (310, 1)\n",
      "step=81300, loss=-3060555520.00\n",
      "(310, 14) (310, 1)\n",
      "step=81400, loss=-4467482112.00\n",
      "(310, 14) (310, 1)\n",
      "step=81500, loss=-3307932672.00\n",
      "(310, 14) (310, 1)\n",
      "step=81600, loss=-3070834176.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=81700, loss=-4253318912.00\n",
      "(310, 14) (310, 1)\n",
      "step=81800, loss=-3079108864.00\n",
      "(310, 14) (310, 1)\n",
      "step=81900, loss=-4494593024.00\n",
      "(310, 14) (310, 1)\n",
      "step=82000, loss=-3328322304.00\n",
      "(310, 14) (310, 1)\n",
      "step=82100, loss=-2605190144.00\n",
      "(310, 14) (310, 1)\n",
      "step=82200, loss=-3336327936.00\n",
      "(310, 14) (310, 1)\n",
      "step=82300, loss=-3097002752.00\n",
      "(310, 14) (310, 1)\n",
      "step=82400, loss=-2614540032.00\n",
      "(310, 14) (310, 1)\n",
      "step=82500, loss=-3104457472.00\n",
      "(310, 14) (310, 1)\n",
      "step=82600, loss=-1432072576.00\n",
      "(310, 14) (310, 1)\n",
      "step=82700, loss=-3112696320.00\n",
      "(310, 14) (310, 1)\n",
      "step=82800, loss=-4056082944.00\n",
      "(310, 14) (310, 1)\n",
      "step=82900, loss=-3120135424.00\n",
      "(310, 14) (310, 1)\n",
      "step=83000, loss=-2408463104.00\n",
      "(310, 14) (310, 1)\n",
      "step=83100, loss=-4560274432.00\n",
      "(310, 14) (310, 1)\n",
      "step=83200, loss=-3131634432.00\n",
      "(310, 14) (310, 1)\n",
      "step=83300, loss=-4336550400.00\n",
      "(310, 14) (310, 1)\n",
      "step=83400, loss=-4576725504.00\n",
      "(310, 14) (310, 1)\n",
      "step=83500, loss=-4346745856.00\n",
      "(310, 14) (310, 1)\n",
      "step=83600, loss=-4587955200.00\n",
      "(310, 14) (310, 1)\n",
      "step=83700, loss=-3150709760.00\n",
      "(310, 14) (310, 1)\n",
      "step=83800, loss=-2432065536.00\n",
      "(310, 14) (310, 1)\n",
      "step=83900, loss=-3157613056.00\n",
      "(310, 14) (310, 1)\n",
      "step=84000, loss=-3161438464.00\n",
      "(310, 14) (310, 1)\n",
      "step=84100, loss=-3165313024.00\n",
      "(310, 14) (310, 1)\n",
      "step=84200, loss=-1460203392.00\n",
      "(310, 14) (310, 1)\n",
      "step=84300, loss=-2675629312.00\n",
      "(310, 14) (310, 1)\n",
      "step=84400, loss=-4135810304.00\n",
      "(310, 14) (310, 1)\n",
      "step=84500, loss=-4140726528.00\n",
      "(310, 14) (310, 1)\n",
      "step=84600, loss=-2455699968.00\n",
      "(310, 14) (310, 1)\n",
      "step=84700, loss=-3438600704.00\n",
      "(310, 14) (310, 1)\n",
      "step=84800, loss=-4654838272.00\n",
      "(310, 14) (310, 1)\n",
      "step=84900, loss=-4420823040.00\n",
      "(310, 14) (310, 1)\n",
      "step=85000, loss=-3199301120.00\n",
      "(310, 14) (310, 1)\n",
      "step=85100, loss=-3454619392.00\n",
      "(310, 14) (310, 1)\n",
      "step=85200, loss=-3206822656.00\n",
      "(310, 14) (310, 1)\n",
      "step=85300, loss=-3210540800.00\n",
      "(310, 14) (310, 1)\n",
      "step=85400, loss=-3215043328.00\n",
      "(310, 14) (310, 1)\n",
      "step=85500, loss=-4692896256.00\n",
      "(310, 14) (310, 1)\n",
      "step=85600, loss=-3222557952.00\n",
      "(310, 14) (310, 1)\n",
      "step=85700, loss=-4703638016.00\n",
      "(310, 14) (310, 1)\n",
      "step=85800, loss=-2722815232.00\n",
      "(310, 14) (310, 1)\n",
      "step=85900, loss=-3487534592.00\n",
      "(310, 14) (310, 1)\n",
      "step=86000, loss=-3236655872.00\n",
      "(310, 14) (310, 1)\n",
      "step=86100, loss=-4218169344.00\n",
      "(310, 14) (310, 1)\n",
      "step=86200, loss=-2735480064.00\n",
      "(310, 14) (310, 1)\n",
      "step=86300, loss=-2738571776.00\n",
      "(310, 14) (310, 1)\n",
      "step=86400, loss=-4498177536.00\n",
      "(310, 14) (310, 1)\n",
      "step=86500, loss=-3511148288.00\n",
      "(310, 14) (310, 1)\n",
      "step=86600, loss=-4508954624.00\n",
      "(310, 14) (310, 1)\n",
      "step=86700, loss=-3264002048.00\n",
      "(310, 14) (310, 1)\n",
      "step=86800, loss=-1505268352.00\n",
      "(310, 14) (310, 1)\n",
      "step=86900, loss=-1506948352.00\n",
      "(310, 14) (310, 1)\n",
      "step=87000, loss=-3274248704.00\n",
      "(310, 14) (310, 1)\n",
      "step=87100, loss=-4534772224.00\n",
      "(310, 14) (310, 1)\n",
      "step=87200, loss=-3539692544.00\n",
      "(310, 14) (310, 1)\n",
      "step=87300, loss=-4791497728.00\n",
      "(310, 14) (310, 1)\n",
      "step=87400, loss=-3548116480.00\n",
      "(310, 14) (310, 1)\n",
      "step=87500, loss=-4555536896.00\n",
      "(310, 14) (310, 1)\n",
      "step=87600, loss=-3556283136.00\n",
      "(310, 14) (310, 1)\n",
      "step=87700, loss=-3301296896.00\n",
      "(310, 14) (310, 1)\n",
      "step=87800, loss=-3304307200.00\n",
      "(310, 14) (310, 1)\n",
      "step=87900, loss=-3568477184.00\n",
      "(310, 14) (310, 1)\n",
      "step=88000, loss=-2553843200.00\n",
      "(310, 14) (310, 1)\n",
      "step=88100, loss=-2556808448.00\n",
      "(310, 14) (310, 1)\n",
      "step=88200, loss=-2559562496.00\n",
      "(310, 14) (310, 1)\n",
      "step=88300, loss=-4597045760.00\n",
      "(310, 14) (310, 1)\n",
      "step=88400, loss=-3327497728.00\n",
      "(310, 14) (310, 1)\n",
      "step=88500, loss=-4856800256.00\n",
      "(310, 14) (310, 1)\n",
      "step=88600, loss=-1536248576.00\n",
      "(310, 14) (310, 1)\n",
      "step=88700, loss=-4867916288.00\n",
      "(310, 14) (310, 1)\n",
      "step=88800, loss=-4873482752.00\n",
      "(310, 14) (310, 1)\n",
      "step=88900, loss=-3345719552.00\n",
      "(310, 14) (310, 1)\n",
      "step=89000, loss=-2582925056.00\n",
      "(310, 14) (310, 1)\n",
      "step=89100, loss=-2585911552.00\n",
      "(310, 14) (310, 1)\n",
      "step=89200, loss=-1546779392.00\n",
      "(310, 14) (310, 1)\n",
      "step=89300, loss=-3361758720.00\n",
      "(310, 14) (310, 1)\n",
      "step=89400, loss=-2594775040.00\n",
      "(310, 14) (310, 1)\n",
      "step=89500, loss=-3369372672.00\n",
      "(310, 14) (310, 1)\n",
      "step=89600, loss=-4665233920.00\n",
      "(310, 14) (310, 1)\n",
      "step=89700, loss=-3376891136.00\n",
      "(310, 14) (310, 1)\n",
      "step=89800, loss=-3645853184.00\n",
      "(310, 14) (310, 1)\n",
      "step=89900, loss=-3383520256.00\n",
      "(310, 14) (310, 1)\n",
      "step=90000, loss=-4685788672.00\n",
      "(310, 14) (310, 1)\n",
      "step=90100, loss=-4945323520.00\n",
      "(310, 14) (310, 1)\n",
      "step=90200, loss=-1564120832.00\n",
      "(310, 14) (310, 1)\n",
      "step=90300, loss=-3665517824.00\n",
      "(310, 14) (310, 1)\n",
      "step=90400, loss=-2623778304.00\n",
      "(310, 14) (310, 1)\n",
      "step=90500, loss=-1569401856.00\n",
      "(310, 14) (310, 1)\n",
      "step=90600, loss=-3409796608.00\n",
      "(310, 14) (310, 1)\n",
      "step=90700, loss=-3682438656.00\n",
      "(310, 14) (310, 1)\n",
      "step=90800, loss=-2881457408.00\n",
      "(310, 14) (310, 1)\n",
      "step=90900, loss=-2638177280.00\n",
      "(310, 14) (310, 1)\n",
      "step=91000, loss=-3693915904.00\n",
      "(310, 14) (310, 1)\n",
      "step=91100, loss=-2890950656.00\n",
      "(310, 14) (310, 1)\n",
      "step=91200, loss=-4468156928.00\n",
      "(310, 14) (310, 1)\n",
      "step=91300, loss=-2649628416.00\n",
      "(310, 14) (310, 1)\n",
      "step=91400, loss=-5016246272.00\n",
      "(310, 14) (310, 1)\n",
      "step=91500, loss=-5021769216.00\n",
      "(310, 14) (310, 1)\n",
      "step=91600, loss=-3447343872.00\n",
      "(310, 14) (310, 1)\n",
      "step=91700, loss=-2661347840.00\n",
      "(310, 14) (310, 1)\n",
      "step=91800, loss=-5038350848.00\n",
      "(310, 14) (310, 1)\n",
      "step=91900, loss=-3730510592.00\n",
      "(310, 14) (310, 1)\n",
      "step=92000, loss=-2919604224.00\n",
      "(310, 14) (310, 1)\n",
      "step=92100, loss=-4512559616.00\n",
      "(310, 14) (310, 1)\n",
      "step=92200, loss=-3742944512.00\n",
      "(310, 14) (310, 1)\n",
      "step=92300, loss=-2929449984.00\n",
      "(310, 14) (310, 1)\n",
      "step=92400, loss=-2682034944.00\n",
      "(310, 14) (310, 1)\n",
      "step=92500, loss=-1604178048.00\n",
      "(310, 14) (310, 1)\n",
      "step=92600, loss=-3486378240.00\n",
      "(310, 14) (310, 1)\n",
      "step=92700, loss=-5088242688.00\n",
      "(310, 14) (310, 1)\n",
      "step=92800, loss=-4546973696.00\n",
      "(310, 14) (310, 1)\n",
      "step=92900, loss=-1611105792.00\n",
      "(310, 14) (310, 1)\n",
      "step=93000, loss=-3775587584.00\n",
      "(310, 14) (310, 1)\n",
      "step=93100, loss=-3780334336.00\n",
      "(310, 14) (310, 1)\n",
      "step=93200, loss=-3783859456.00\n",
      "(310, 14) (310, 1)\n",
      "step=93300, loss=-4858443264.00\n",
      "(310, 14) (310, 1)\n",
      "step=93400, loss=-3792584192.00\n",
      "(310, 14) (310, 1)\n",
      "step=93500, loss=-1621611776.00\n",
      "(310, 14) (310, 1)\n",
      "step=93600, loss=-4874053120.00\n",
      "(310, 14) (310, 1)\n",
      "step=93700, loss=-3804887552.00\n",
      "(310, 14) (310, 1)\n",
      "step=93800, loss=-3531863552.00\n",
      "(310, 14) (310, 1)\n",
      "step=93900, loss=-5154875904.00\n",
      "(310, 14) (310, 1)\n",
      "step=94000, loss=-3538491392.00\n",
      "(310, 14) (310, 1)\n",
      "step=94100, loss=-4900204032.00\n",
      "(310, 14) (310, 1)\n",
      "step=94200, loss=-4905250304.00\n",
      "(310, 14) (310, 1)\n",
      "step=94300, loss=-4910523904.00\n",
      "(310, 14) (310, 1)\n",
      "step=94400, loss=-3833160192.00\n",
      "(310, 14) (310, 1)\n",
      "step=94500, loss=-5187456512.00\n",
      "(310, 14) (310, 1)\n",
      "step=94600, loss=-2745989632.00\n",
      "(310, 14) (310, 1)\n",
      "step=94700, loss=-2748880128.00\n",
      "(310, 14) (310, 1)\n",
      "step=94800, loss=-5204063744.00\n",
      "(310, 14) (310, 1)\n",
      "step=94900, loss=-2754913536.00\n",
      "(310, 14) (310, 1)\n",
      "step=95000, loss=-4947423232.00\n",
      "(310, 14) (310, 1)\n",
      "step=95100, loss=-3861974784.00\n",
      "(310, 14) (310, 1)\n",
      "step=95200, loss=-4957708800.00\n",
      "(310, 14) (310, 1)\n",
      "step=95300, loss=-3588400128.00\n",
      "(310, 14) (310, 1)\n",
      "step=95400, loss=-1654646528.00\n",
      "(310, 14) (310, 1)\n",
      "step=95500, loss=-3594885120.00\n",
      "(310, 14) (310, 1)\n",
      "step=95600, loss=-3882041600.00\n",
      "(310, 14) (310, 1)\n",
      "step=95700, loss=-3602297856.00\n",
      "(310, 14) (310, 1)\n",
      "step=95800, loss=-4694059520.00\n",
      "(310, 14) (310, 1)\n",
      "step=95900, loss=-3610504192.00\n",
      "(310, 14) (310, 1)\n",
      "step=96000, loss=-4998850560.00\n",
      "(310, 14) (310, 1)\n",
      "step=96100, loss=-5275328000.00\n",
      "(310, 14) (310, 1)\n",
      "step=96200, loss=-4713999872.00\n",
      "(310, 14) (310, 1)\n",
      "step=96300, loss=-3910370816.00\n",
      "(310, 14) (310, 1)\n",
      "step=96400, loss=-3059695872.00\n",
      "(310, 14) (310, 1)\n",
      "step=96500, loss=-5025068544.00\n",
      "(310, 14) (310, 1)\n",
      "step=96600, loss=-3066101760.00\n",
      "(310, 14) (310, 1)\n",
      "step=96700, loss=-3640109824.00\n",
      "(310, 14) (310, 1)\n",
      "step=96800, loss=-5040940544.00\n",
      "(310, 14) (310, 1)\n",
      "step=96900, loss=-5319393280.00\n",
      "(310, 14) (310, 1)\n",
      "step=97000, loss=-3938235904.00\n",
      "(310, 14) (310, 1)\n",
      "step=97100, loss=-3655162112.00\n",
      "(310, 14) (310, 1)\n",
      "step=97200, loss=-2821692160.00\n",
      "(310, 14) (310, 1)\n",
      "step=97300, loss=-2824664576.00\n",
      "(310, 14) (310, 1)\n",
      "step=97400, loss=-4773368320.00\n",
      "(310, 14) (310, 1)\n",
      "step=97500, loss=-3959767040.00\n",
      "(310, 14) (310, 1)\n",
      "step=97600, loss=-5083180544.00\n",
      "(310, 14) (310, 1)\n",
      "step=97700, loss=-3967069184.00\n",
      "(310, 14) (310, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step=97800, loss=-1696432896.00\n",
      "(310, 14) (310, 1)\n",
      "step=97900, loss=-3686692864.00\n",
      "(310, 14) (310, 1)\n",
      "step=98000, loss=-1699975552.00\n",
      "(310, 14) (310, 1)\n",
      "step=98100, loss=-5386233344.00\n",
      "(310, 14) (310, 1)\n",
      "step=98200, loss=-5391733248.00\n",
      "(310, 14) (310, 1)\n",
      "step=98300, loss=-5119825408.00\n",
      "(310, 14) (310, 1)\n",
      "step=98400, loss=-5124865536.00\n",
      "(310, 14) (310, 1)\n",
      "step=98500, loss=-3709297664.00\n",
      "(310, 14) (310, 1)\n",
      "step=98600, loss=-3130167040.00\n",
      "(310, 14) (310, 1)\n",
      "step=98700, loss=-4008613120.00\n",
      "(310, 14) (310, 1)\n",
      "step=98800, loss=-4012062464.00\n",
      "(310, 14) (310, 1)\n",
      "step=98900, loss=-3723672832.00\n",
      "(310, 14) (310, 1)\n",
      "step=99000, loss=-2874457600.00\n",
      "(310, 14) (310, 1)\n",
      "step=99100, loss=-5161757696.00\n",
      "(310, 14) (310, 1)\n",
      "step=99200, loss=-5447015936.00\n",
      "(310, 14) (310, 1)\n",
      "step=99300, loss=-4032519168.00\n",
      "(310, 14) (310, 1)\n",
      "step=99400, loss=-2886059008.00\n",
      "(310, 14) (310, 1)\n",
      "step=99500, loss=-4041290240.00\n",
      "(310, 14) (310, 1)\n",
      "step=99600, loss=-3162045440.00\n",
      "(310, 14) (310, 1)\n",
      "step=99700, loss=-2894754048.00\n",
      "(310, 14) (310, 1)\n",
      "step=99800, loss=-3168343808.00\n",
      "(310, 14) (310, 1)\n",
      "step=99900, loss=-4056643072.00\n",
      "(310, 14) (310, 1)\n",
      "step=100000, loss=-5208398336.00\n",
      "(310, 14) (310, 1)\n",
      "Estimated: a1=83242.32, a2=99696.94, b=4353.96\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 14), name=\"x\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "W = tf.Variable(tf.zeros((14, 1),tf.float32), name=\"W\")\n",
    "b = tf.Variable(.0, name=\"b\")\n",
    "\n",
    "u = tf.matmul(x, W) + b\n",
    "y = tf.sigmoid(u)\n",
    "\n",
    "#tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels = u, logits = y_)\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "#TensorBoardで追跡する変数を定義\n",
    "#with tf.name_scope('summary'):\n",
    "tf.summary.scalar('loss', loss)\n",
    "writer = tf.summary.FileWriter('./logs', sess.graph)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "y_tra = y_train.reshape(-1,1)\n",
    "\n",
    "for i in range(200000):\n",
    "    \n",
    "    idx = random.randint(0, 9)\n",
    "    batch_xs, batch_ys = X_train[np.where(groups==idx)].astype(np.float32),y_train[np.where(groups==idx)].reshape(-1,1)\n",
    "    opt_, l, W_ = sess.run([opt, loss, W], feed_dict={x: batch_xs, y_:batch_ys})\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\"step=%3d, loss=%.2f\" % (i + 1, l))\n",
    "        print(X_train.shape,y_train.reshape(-1,1).shape)\n",
    "        loss_val,foo = sess.run([loss,merged], feed_dict={x: X_train, y_: y_train.reshape(-1,1)})\n",
    "        writer.add_summary(foo,i)\n",
    "        \n",
    "est_a, est_b = sess.run([W, b], feed_dict={x: X_test, y_: y_test.reshape(-1,1)})\n",
    "print(\"Estimated: a1=%6.2f, a2=%6.2f, b=%6.2f\" % (est_a[0], est_a[1], est_b))   \n",
    "\n",
    "new_y = sess.run(y, feed_dict={x: X_test})\n",
    "print(new_y)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31, 14), (31, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_xs.shape,batch_ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10 13]\n",
      " [ 4  4]] 0.451612903226\n"
     ]
    }
   ],
   "source": [
    "pred = new_y.T[0] > 0.5\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(confusion_matrix(y_test, pred), accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features=3, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000,random_state=0,max_depth=2,max_features=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.694\n",
      "0.645\n",
      "[ 0.0346702   0.02555176  0.07519289  0.0291062   0.0358884   0.03466751\n",
      "  0.11215814  0.07157213  0.11955964  0.09250014  0.16021424  0.05785689\n",
      "  0.09030374  0.06075811]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7fbbc5d6d1d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import numpy as np\n",
    "\n",
    "fp = font_manager.FontProperties(fname=\"/home/fukuyama/IPAfont00303/ipag.ttf\",size=20)\n",
    "\n",
    "print(\"{:.3f}\".format(clf.score(X_train,y_train)))\n",
    "print(\"{:.3f}\".format(clf.score(X_test,y_test)))\n",
    "\n",
    "print(\"{}\".format(clf.feature_importances_))\n",
    "\n",
    "n_featrures = X_train.shape[1]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "n_features = len(traindf.drop(dlist,axis=1).columns)\n",
    "plt.barh(range(n_featrures),clf.feature_importances_,align='center')\n",
    "plt.yticks(np.arange(n_features),traindf.drop(dlist,axis=1).columns,fontproperties=fp)\n",
    "plt.xlabel(\"Feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation accuracy: 0.65\n",
      "Test set score: 0.67\n",
      "Best parameters : {'svm__class_weight': 'balanced', 'svm__gamma': 0.01, 'svm__C': 1}\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross validation\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "pipe = Pipeline([('scaler',StandardScaler()),(\"svm\",SVC(random_state=0))])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "params = {'svm__C':[0.0001,0.001,0.01,0.1,1,10,100],'svm__gamma':[0.001,0.01,0.1,1,10,100],'svm__class_weight':[None,'balanced']}\n",
    "groups = sum([[label]*31 for label in range(10)],[])\n",
    "gkfold = list(GroupKFold(n_splits=10).split(X_train,y_train,groups))\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid = params, cv = gkfold, scoring='accuracy',n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print('Best cross-validation accuracy: {:.2f}'.format(grid.best_score_))\n",
    "print('Test set score: {:.2f}'.format(grid.score(X_train,y_train)))\n",
    "print('Best parameters : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=10.0, gamma=0.01, random_state=0, probability=True, class_weight=None)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=0, shrinking=True, tol=0.001,\n",
       "  verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64516129032258063"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       曇or雨       0.75      0.78      0.77        23\n",
      "          晴       0.29      0.25      0.27         8\n",
      "\n",
      "avg / total       0.63      0.65      0.64        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test, pred,target_names=['曇or雨','晴']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[18  5]\n",
      " [ 6  2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fukuyama/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/matplotlib/font_manager.py:1297: UserWarning: findfont: Font family ['ipag'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.78  0.22]\n",
      " [ 0.75  0.25]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAJCCAYAAADky0LWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFsRJREFUeJzt3W2M5Wd53/Hf1d24YQkdU+EkZG113Ai5QmxV0DQioUor\nTCuXRXFf5AVItKGlsvKiLUkToaWRGvVFpZWK0rRKlGoFBNJQUOXQFrFJC8qDUCViMTYPa2wgFLbG\nG1MboQwolmpwrr6YSbxsvez4XGfOzNn9fKSRZ87D3Pfcmv37u/ecube6OwAALObPHfYEAADWmZgC\nABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwMDxaz2gqt6V5HVJHu/ul11x388keXuS\nW7r7q9f6XC960Yt6c3NzwakCAKzO/fff/9XuvuVaj7tmTCV5d5JfSvJrl99YVbcl+TtJHtnvpDY3\nN7O9vb3fhwMAHJqq+t/7edw1f8zX3R9N8rVnuevfJnlrEv+4HwBww1roNVNVdXeSS939qX089p6q\n2q6q7SeeeGKR4QAAjqznHFNVdSLJv0jyL/fz+O4+191b3b11yy3X/LEjAMBaWWRn6geT3J7kU1V1\nMcmtSR6oqu9f5sQAANbBfl6A/m26+0KS7/3Tj/eCams/v80HAHC9uebOVFW9L8nHktxRVY9W1ZsP\nfloAAOvhmjtT3f2Ga9y/ubTZAACsGSegAwAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IK\nAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBg4PgqB7twaSebZ86vckhYKxfP\nnj7sKQDwHNmZAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoA\nYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAG\nxBQAwICYAgAYEFMAAANiCgBgQEwBAAwcX+Vgp05uZPvs6VUOCQBwoOxMAQAMiCkAgAExBQAwIKYA\nAAbEFADAgJgCABhY6dEIFy7tZPPM+VUOCfCcXXSEC/Ac2JkCABgQUwAAA2IKAGBATAEADIgpAIAB\nMQUAMCCmAAAGxBQAwICYAgAYEFMAAAPXjKmqeldVPV5VD15227+pqs9W1aer6r9U1c0HO00AgKNp\nPztT705y1xW3fSTJy7r7ryb5fJK3LXleAABr4Zox1d0fTfK1K277cHd/a+/D309y6wHMDQDgyFvG\na6b+UZLfutqdVXVPVW1X1fbTT+4sYTgAgKNjFFNV9XNJvpXkvVd7THef6+6t7t46dmJjMhwAwJFz\nfNEnVtWbkrwuyZ3d3UubEQDAGlkopqrqriRvTfI3u/vJ5U4JAGB97OdohPcl+ViSO6rq0ap6c5Jf\nSvKCJB+pqk9W1X844HkCABxJ19yZ6u43PMvN7zyAuQAArB0noAMADIgpAIABMQUAMCCmAAAGxBQA\nwICYAgAYEFMAAANiCgBgYOF/m28Rp05uZPvs6VUOCQBwoOxMAQAMiCkAgAExBQAwIKYAAAbEFADA\ngJgCABgQUwAAAys9Z+rCpZ1snjm/yiHhyLjojDWA65KdKQCAATEFADAgpgAABsQUAMCAmAIAGBBT\nAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUA\nMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABo6vcrBTJzeyffb0KocE\nADhQdqYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADKz0aIQLl3ayeeb8KocEAK4jF4/gEUt2pgAA\nBsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAwDVjqqreVVWPV9WDl932\nF6vqI1X1B3v/feHBThMA4Gjaz87Uu5PcdcVtZ5L8dne/JMlv730MAHDDuWZMdfdHk3ztipvvTvKe\nvfffk+TvLXleAABrYdHXTH1fdz+29/5XknzfkuYDALBWxi9A7+5O0le7v6ruqartqtp++smd6XAA\nAEfKojH1f6rqxUmy99/Hr/bA7j7X3VvdvXXsxMaCwwEAHE2LxtQHk/zE3vs/keS/LWc6AADrZT9H\nI7wvyceS3FFVj1bVm5OcTfK3q+oPkrxm72MAgBvO8Ws9oLvfcJW77lzyXAAA1o4T0AEABsQUAMCA\nmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAaueQL6Mp06uZHts6dXOSQAwIGyMwUAMCCm\nAAAGxBQAwICYAgAYEFMAAANiCgBgYKVHI1y4tJPNM+dXOSTA0l10xAtwGTtTAAADYgoAYEBMAQAM\niCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICY\nAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkA\ngIHjqxzs1MmNbJ89vcohAQAOlJ0pAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAAMrPRrhwqWdbJ45\nv8ohAVhTFx2lw5qwMwUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAA\nBkYxVVU/XVWfqaoHq+p9VfXdy5oYAMA6WDimqupkkn+WZKu7X5bkWJLXL2tiAADrYPpjvuNJnldV\nx5OcSPKH8ykBAKyPhWOquy8leXuSR5I8lmSnuz985eOq6p6q2q6q7aef3Fl8pgAAR9Dkx3wvTHJ3\nktuT/ECS51fVG698XHef6+6t7t46dmJj8ZkCABxBkx/zvSbJl7r7ie7+ZpIPJPmR5UwLAGA9TGLq\nkSSvrKoTVVVJ7kzy8HKmBQCwHiavmbovyb1JHkhyYe9znVvSvAAA1sLxyZO7++eT/PyS5gIAsHac\ngA4AMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAwOgH9uTp1ciPbZ0+vckgA\ngANlZwoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAwEqPRrhwaSebZ86vckhg4KKjTACuyc4UAMCA\nmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgp\nAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIA\nGBBTAAADx1c52KmTG9k+e3qVQwIAHCg7UwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwMBK\nz5m6cGknm2fOr3JIAA7ARWcGwp+xMwUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCA\nATEFADAwiqmqurmq7q2qz1bVw1X1w8uaGADAOpj+czL/Lsl/7+4fr6qbkpxYwpwAANbGwjFVVRtJ\nfjTJm5Kku59K8tRypgUAsB4mP+a7PckTSX61qj5RVe+oqucvaV4AAGthElPHk7wiya9098uT/HGS\nM1c+qKruqartqtp++smdwXAAAEfPJKYeTfJod9+39/G92Y2rb9Pd57p7q7u3jp3YGAwHAHD0LBxT\n3f2VJF+uqjv2brozyUNLmRUAwJqY/jbfP03y3r3f5Ptikn84nxIAwPoYxVR3fzLJ1pLmAgCwdpyA\nDgAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMDD952Sek1MnN7J99vQqhwQA\nOFB2pgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMrPRohAuXdrJ55vwqh+SAXHTEBQAksTMFADAi\npgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IK\nAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAA\nBsQUAMCAmAIAGDi+ysFOndzI9tnTqxwSAOBA2ZkCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMLDS\noxEuXNrJ5pnzqxySFbnoyAsAblB2pgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAw\nIKYAAAbEFADAwDimqupYVX2iqj60jAkBAKyTZexMvSXJw0v4PAAAa2cUU1V1a5LTSd6xnOkAAKyX\n6c7ULyZ5a5I/WcJcAADWzsIxVVWvS/J4d99/jcfdU1XbVbX99JM7iw4HAHAkTXamXpXkx6rqYpL3\nJ3l1Vf36lQ/q7nPdvdXdW8dObAyGAwA4ehaOqe5+W3ff2t2bSV6f5He6+41LmxkAwBpwzhQAwMDx\nZXyS7v69JL+3jM8FALBO7EwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAM\nLOUE9P06dXIj22dPr3JIAIADZWcKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwMBKj0a4cGknm2fO\nr3JILnPRsRQAsHR2pgAABsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADA\ngJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyI\nKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADx1c52KmTG9k+e3qVQwIAHCg7UwAAA2IKAGBATAEA\nDIgpAIABMQUAMCCmAAAGVno0woVLO9k8c36VQwIrdNHRJ8ANyM4UAMCAmAIAGBBTAAADYgoAYEBM\nAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABhYOKaq6raq+t2qeqiqPlNVb1nmxAAA1sHk3+b7VpKf\n6e4HquoFSe6vqo9090NLmhsAwJG38M5Udz/W3Q/svf+NJA8nObmsiQEArIOlvGaqqjaTvDzJfc9y\n3z1VtV1V208/ubOM4QAAjoxxTFXV9yT5jSQ/1d1fv/L+7j7X3VvdvXXsxMZ0OACAI2UUU1X1XdkN\nqfd29weWMyUAgPUx+W2+SvLOJA939y8sb0oAAOtjsjP1qiR/P8mrq+qTe2+vXdK8AADWwsJHI3T3\n/0xSS5wLAMDacQI6AMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYAAAYWPrRzEadObmT7\n7OlVDgkAcKDsTAEADIgpAIABMQUAMCCmAAAGxBQAwICYAgAYEFMAAAMrPWfqwqWdbJ45v8ohr3sX\nndsFAIfKzhQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAAD\nYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAIABMQUAMCCm\nAAAGxBQAwICYAgAYEFMAAAPHVznYqZMb2T57epVDAgAcKDtTAAADYgoAYEBMAQAMiCkAgAExBQAw\nIKYAAAZWejTChUs72TxzfpVDckAuOuICAJLYmQIAGBFTAAADYgoAYEBMAQAMiCkAgAExBQAwIKYA\nAAbEFADAgJgCABgQUwAAA6OYqqq7qupzVfWFqjqzrEkBAKyLhWOqqo4l+eUkfzfJS5O8oapeuqyJ\nAQCsg8nO1A8l+UJ3f7G7n0ry/iR3L2daAADrYRJTJ5N8+bKPH927DQDghnHgL0Cvqnuqaruqtp9+\ncueghwMAWKlJTF1KcttlH9+6d9u36e5z3b3V3VvHTmwMhgMAOHomMfXxJC+pqtur6qYkr0/yweVM\nCwBgPRxf9Ind/a2q+idJ/keSY0ne1d2fWdrMAADWwMIxlSTd/ZtJfnNJcwEAWDtOQAcAGBBTAAAD\nYgoAYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgYnYD+XJ06uZHts6dXOSQAwIGyMwUAMCCm\nAAAGxBQAwICYAgAYEFMAAANiCgBgQEwBAAyIKQCAATEFADAgpgAABsQUAMCAmAIAGBBTAAADYgoA\nYEBMAQAMiCkAgAExBQAwIKYAAAbEFADAgJgCABgQUwAAA2IKAGBATAEADIgpAICB6u7VDVb1jSSf\nW9mAR9eLknz1sCdxRFiLXdZhl3V4hrXYZR12WYdnrHIt/lJ333KtBx1fxUwu87nu3lrxmEdOVW1b\nh13WYpd12GUdnmEtdlmHXdbhGUdxLfyYDwBgQEwBAAysOqbOrXi8o8o6PMNa7LIOu6zDM6zFLuuw\nyzo848itxUpfgA4AcL3xYz4AgIGlxFRV3VVVn6uqL1TVmWe5v6rq3+/d/+mqesV+n7tuFl2Lqrqt\nqn63qh6qqs9U1VtWP/vlmXxP7N1/rKo+UVUfWt2sl2/4Z+Pmqrq3qj5bVQ9X1Q+vdvbLNVyLn977\nc/FgVb2vqr57tbNfnn2sw1+pqo9V1f+tqp99Ls9dJ4uuw/V2rUxm3xN7998o18vv9GfjcK+X3T16\nS3Isyf9K8peT3JTkU0leesVjXpvkt5JUklcmuW+/z12nt+FavDjJK/bef0GSz6/rWkzW4bL7/3mS\n/5TkQ4f99RzWOiR5T5J/vPf+TUluPuyv6TDWIsnJJF9K8ry9j/9zkjcd9td0gOvwvUn+epJ/neRn\nn8tz1+VtuA7XzbVyuhaX3X+jXC+vug6Hfb1cxs7UDyX5Qnd/sbufSvL+JHdf8Zi7k/xa7/r9JDdX\n1Yv3+dx1svBadPdj3f1AknT3N5I8nN3/iayjyfdEqurWJKeTvGOVkz4AC69DVW0k+dEk70yS7n6q\nu/9olZNfstH3RHbPxHteVR1PciLJH65q4kt2zXXo7se7++NJvvlcn7tGFl6H6+xamcy+J26o6+XV\n1uEoXC+XEVMnk3z5so8fzf//jX21x+znuetkshZ/pqo2k7w8yX1Ln+FqTNfhF5O8NcmfHNQEV2Sy\nDrcneSLJr+5t37+jqp5/kJM9YAuvRXdfSvL2JI8keSzJTnd/+ADnepAm17zr6Xq5lK/lOrhWJvO1\nuJGul1dz6NdLL0A/Yqrqe5L8RpKf6u6vH/Z8Vq2qXpfk8e6+/7DncsiOJ3lFkl/p7pcn+eMka/0a\nmUVV1Quz+zfU25P8QJLnV9UbD3dWHLYb/VqZuF5e5tCvl8uIqUtJbrvs41v3btvPY/bz3HUyWYtU\n1Xdl9+Lw3u7+wAHO86BN1uFVSX6sqi5md5v31VX16wc31QM1WYdHkzza3X/6N+57s3uxWFeTtXhN\nki919xPd/c0kH0jyIwc414M0ueZdT9fL0ddyHV0rk9la3GjXy6s59OvlMmLq40leUlW3V9VNSV6f\n5INXPOaDSf7B3m/rvDK72/SP7fO562Thtaiqyu7Pex/u7l9Y7bSXbuF16O63dfet3b2597zf6e51\n3YWYrMNXkny5qu7Ye9ydSR5a2cyXb3KdeCTJK6vqxN6fkzuz+zqZdTS55l1P18uFv5br7FqZDNbi\nBrxePqsjcb1cxqvYs/tbOJ/P7ivxf27vtp9M8pN771eSX967/0KSre/03HV+W3QtkvyNJJ3k00k+\nuff22sP+eg7je+Kyz/G3ssa/nTJdhyR/Lcn23vfEf03ywsP+eg5xLf5Vks8meTDJf0zy5w/76znA\ndfj+7P5N++tJ/mjv/b9wteeu69ui63C9XSun3xOXfY4b4Xr5nf5sHOr10gnoAAADXoAOADAgpgAA\nBsQUAMCAmAIAGBBTAAADYgoAYEBMAQAMiCkAgIH/B3jW3/O4MN/8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbc5d00cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAw8AAAJQCAYAAADIc1hAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnRNkdyPfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbc2947cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAGoCAYAAADrUoo3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnfENf2A7ItsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbc2987a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAGoCAYAAAANe0FzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUREMooCk4iIZJT/Bz9Bzn017/edAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbbc2902c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "        \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[i for i in range(2)],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(6, 6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[i for i in range(2)], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [d.strftime('%Y/%m/%d') for d in traindf[col].index.tolist()]\n",
    "weather = traindf[col].values.tolist()\n",
    "\n",
    "wd = {i:w for i,w in zip(idx,weather)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "baysedict = defaultdict(int)\n",
    "\n",
    "for today,w in wd.items():\n",
    "    ystday = (datetime.datetime.strptime(today, '%Y/%m/%d') - datetime.timedelta(days=1)).strftime('%Y/%m/%d')\n",
    "    \n",
    "    if ystday in wd.keys():\n",
    "        baysedict[(wd[ystday],wd[today])] += 1\n",
    "        \n",
    "\n",
    "SUM = sum(baysedict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(int, {(0, 0): 103, (0, 1): 66, (1, 0): 63, (1, 1): 68}),\n",
       " 0.3905,\n",
       " 0.5191,\n",
       " 0.4467)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baysedict,round(66/(103+66),4),round(68/(63+68),4),round((66+68)/(103+66+63+68),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def naivebayse(df):\n",
    "    \n",
    "    plist = []\n",
    "    \n",
    "    col = '天気概況(昼：06時〜18時)'\n",
    "    \n",
    "    idx = [d.strftime('%Y/%m/%d') for d in df[col].index.tolist()]\n",
    "    weather = df[col].values.tolist()\n",
    "    wd = {i:w for i,w in zip(idx,weather)}\n",
    "    \n",
    "    for today,w in wd.items():\n",
    "        ystday = (datetime.datetime.strptime(today, '%Y/%m/%d') - datetime.timedelta(days=1)).strftime('%Y/%m/%d')\n",
    "    \n",
    "        if ystday in wd.keys():\n",
    "            if   wd[ystday] == 0:\n",
    "                plist.append(0.3905)\n",
    "            elif wd[ystday] == 1:\n",
    "                plist.append(0.5191)\n",
    "        else:\n",
    "            plist.append(0.4467)\n",
    "    return plist\n",
    "\n",
    "nb = naivebayse(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65957403074804466, 0.63876859534007435, 0.60697667020555324)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "log_loss(y_test,clf.predict_proba(X_test)),log_loss(y_test,[0.4355 for i in range(31)]),log_loss(y_test,nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "学習のさせ方 : \n",
    "過去30日のデータをvalidation dataとして訓練する．\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
